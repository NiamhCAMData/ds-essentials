[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Digital Scholarship & Data Science Essentials for Library Professionals",
    "section": "",
    "text": "Welcome\nDigital Scholarship and Data Science Essentials for Library Professionals is an open and collaboratively curated training reference resource. It aims to make it easier for LIBER library professionals to gain a concise overview of the new technologies that underpin digital scholarship and data science practice in research libraries today, and find trusted training materials recommendations to start their professional learning journey.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#our-aims",
    "href": "index.html#our-aims",
    "title": "Digital Scholarship & Data Science Essentials for Library Professionals",
    "section": "Our Aims",
    "text": "Our Aims\n\n\n\nDS Essentials Aims Summarised",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#who-is-it-for",
    "href": "index.html#who-is-it-for",
    "title": "Digital Scholarship & Data Science Essentials for Library Professionals",
    "section": "Who is it for?",
    "text": "Who is it for?\nAre you someone working in or around research libraries with an interest in learning more about how to do cool and interesting things with digital collections and data at your institution? Wondering how data science techniques can help you in your work? Are you interested in gaining valuable digital literacy skills and knowledge to support emerging areas of modern scholarship such as Digital Humanities? Do you need some of the technology jargon you hear about these days demystified?\nThen this resource is for you!\nIt is very important to us that this resource is inclusive and intellectually accessible, challenging but not terrifying and as such we focus primarily on an introductory audience where no programming or particular digital skills are required.\nThough written primarily from the research library professional perspective these guides will be useful for anyone currently (or aspiring to be) working in and around digital collections and data in heritage institutions:\n\nLibrary & Information Science students\nProject managers\nDevelopers\nInformation specialists\nMetadata Managers\nSubject librarians\nSystem librarians\nInstitutional leadership\n\nAnd so many more!",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#why-this-resource",
    "href": "index.html#why-this-resource",
    "title": "Digital Scholarship & Data Science Essentials for Library Professionals",
    "section": "Why this resource?",
    "text": "Why this resource?\nOver the past few decades, the development of excellent self-paced tutorials and training materials relating to undertaking digital scholarship and data science in libraries have proliferated online.\nFor library professionals who are relatively new to this area however, it can be hard to know where to begin! Without knowing a little bit about the context of how new technologies are being deployed in research libraries, this dearth of resources can seem quite daunting. Even if you might have an idea of what learning you’d like to undertake, it can be difficult and time consuming to try and navigate the wealth of individual training resources out there on your own.\nDigital Scholarship and Data Science Essentials for Library Professionals is a training reference resource we have developed to remove some of the barrier of having to hunt for recommended training and resources to get you on the learning ladder.\nFrom working with data, data management, digital storytelling, handwritten recognition technologies and more, our Topic Guides provide contextualised and gentle introductions, written from the library practitioners perspective, to a wide range of key topics and technologies relevant to working innovatively with our digital collections and data.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#what-are-topic-guides",
    "href": "index.html#what-are-topic-guides",
    "title": "Digital Scholarship & Data Science Essentials for Library Professionals",
    "section": "What are Topic Guides?",
    "text": "What are Topic Guides?\nTopic Guides are the heart and soul of Digital Scholarship and Data Science Essentials for Library Professionals. The aim of each is to provide research library professionals with a gentle and concise introduction to the key topics in this area today. They offer those with no prior knowledge, quick and curated guidance to personally recommended hands-on tutorials, use-cases, articles, videos, networks and communities of practice to deepen learning.\nEach Topic Guide follows a fixed structure, consisting of five components in order to make it easier to quickly find what you might need: - Introduction to the topic - Relevance to the library sector (Case studies/Use cases) - Hands-on activities and other self-guided tutorial(s) - Recommended Reading & Viewing - Taking the next steps (Communities of Practice)",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#how-to-use-this-resource",
    "href": "index.html#how-to-use-this-resource",
    "title": "Digital Scholarship & Data Science Essentials for Library Professionals",
    "section": "How to use this resource",
    "text": "How to use this resource\nThis resource has a dual purpose; it is written as a tool for self-study but also as a guide for individuals and institutions interested in establishing their own local training programmes.\nAs a self-study resource, we hope it can serve as a useful first point of entry into complex topics in digital scholarship and data science and their application in the library world. It is not meant to be completed in any particular order, rather, learners are invited to jump in and out of individual topic guides as personal curiosity or practical need dictates.\nThe materials here can also be utilised in group study, as part of a reading group or even a hands-on Hack & Yack. See our special section on “How to start your own training programme” for some tips and tricks from British Library Digital Research Team colleagues on utilising the materials referenced here at your own library or within your network.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "topicguides.html",
    "href": "topicguides.html",
    "title": "TOPIC GUIDES",
    "section": "",
    "text": "Topic Guides are the heart and soul of Digital Scholarship and Data Science Essentials for Library Professionals. The aim of each is to provide research library professionals with a gentle and concise introduction to the key topics in this area today. They offer those with no prior knowledge, quick and curated guidance to personally recommended hands-on tutorials, use-cases, articles, videos, networks and communities of practice to deepen learning.\nEach Topic Guide follows a fixed structure, consisting of a descriptive header and five key components in order to make it easier to quickly find the information you might need:\n\nIntroduction to the topic\nRelevance to the library sector (case studies/use cases)\nHands-on activities and other self-guided tutorial(s)\nRecommended reading & viewing\nTaking the next steps (finding Communities of Practice)\n\nThe guides are not presented, nor meant to be completed, in any particular order, rather, you are invited to jump in and out of individual topics as personal curiosity or practical need dictates.\nThe Topic Guide list in this first edition draws heavily on the existing skills framework and topics covered in the British Library’s Digital Scholarship Training Programme, as well as those recommended by attendees of a series of development workshops held with LIBER working groups throughout 2023.",
    "crumbs": [
      "**TOPIC GUIDES**"
    ]
  },
  {
    "objectID": "getting-started-with-programming.html",
    "href": "getting-started-with-programming.html",
    "title": "Getting Started With Programming",
    "section": "",
    "text": "Introduction\naergergdfvdf",
    "crumbs": [
      "Getting Started With Programming"
    ]
  },
  {
    "objectID": "getting-started-with-programming.html#relevance-to-the-library-sector",
    "href": "getting-started-with-programming.html#relevance-to-the-library-sector",
    "title": "Getting Started With Programming",
    "section": "Relevance to the Library Sector",
    "text": "Relevance to the Library Sector\naergaergaerg",
    "crumbs": [
      "Getting Started With Programming"
    ]
  },
  {
    "objectID": "getting-started-with-programming.html#hands-on-exercises-self-guided-tutorials",
    "href": "getting-started-with-programming.html#hands-on-exercises-self-guided-tutorials",
    "title": "Getting Started With Programming",
    "section": "Hands-On Exercises & Self-Guided Tutorials",
    "text": "Hands-On Exercises & Self-Guided Tutorials\naergeargaerg",
    "crumbs": [
      "Getting Started With Programming"
    ]
  },
  {
    "objectID": "getting-started-with-programming.html#recommended-reading-further-resources",
    "href": "getting-started-with-programming.html#recommended-reading-further-resources",
    "title": "Getting Started With Programming",
    "section": "Recommended Reading & Further Resources",
    "text": "Recommended Reading & Further Resources\nragergeargaergaer",
    "crumbs": [
      "Getting Started With Programming"
    ]
  },
  {
    "objectID": "r.html",
    "href": "r.html",
    "title": "R",
    "section": "",
    "text": "All things R :)",
    "crumbs": [
      "Getting Started With Programming",
      "R"
    ]
  },
  {
    "objectID": "python.html",
    "href": "python.html",
    "title": "Python",
    "section": "",
    "text": "All things Python :)",
    "crumbs": [
      "Getting Started With Programming",
      "Python"
    ]
  },
  {
    "objectID": "ml-ai.html",
    "href": "ml-ai.html",
    "title": "Machine Learning and AI in Libraries",
    "section": "",
    "text": "But first, a quick quiz!\nWhich of the following do you think would use Machine Learning?\nIf you answered 2, 3, 6 & 7 you are correct! The others could all be easily programmed using a simple set of easily defined rules.",
    "crumbs": [
      "Machine Learning and AI in Libraries"
    ]
  },
  {
    "objectID": "ml-ai.html#relevance-to-the-library-sector",
    "href": "ml-ai.html#relevance-to-the-library-sector",
    "title": "Machine Learning and AI in Libraries",
    "section": "Relevance to the Library Sector",
    "text": "Relevance to the Library Sector\nCover NLP and Computer Vision here and include Transkribus case study as an example of how models and algorithms work.\n\nLet’s say you have 20,000 pages of handwritten manuscripts that you would like to transcribe and turn into machine readable text to allow for better search for your researchers. A task of this scale would be far too for any one, or even two, staff members to attempt. This is where machine learning comes in….",
    "crumbs": [
      "Machine Learning and AI in Libraries"
    ]
  },
  {
    "objectID": "ml-ai.html#hands-on-activities-self-guided-tutorials",
    "href": "ml-ai.html#hands-on-activities-self-guided-tutorials",
    "title": "Machine Learning and AI in Libraries",
    "section": "Hands-On Activities & Self-Guided Tutorials",
    "text": "Hands-On Activities & Self-Guided Tutorials",
    "crumbs": [
      "Machine Learning and AI in Libraries"
    ]
  },
  {
    "objectID": "ml-ai.html#recommended-reading-viewing",
    "href": "ml-ai.html#recommended-reading-viewing",
    "title": "Machine Learning and AI in Libraries",
    "section": "Recommended Reading & Viewing",
    "text": "Recommended Reading & Viewing",
    "crumbs": [
      "Machine Learning and AI in Libraries"
    ]
  },
  {
    "objectID": "ml-ai.html#taking-things-further",
    "href": "ml-ai.html#taking-things-further",
    "title": "Machine Learning and AI in Libraries",
    "section": "Taking things further",
    "text": "Taking things further",
    "crumbs": [
      "Machine Learning and AI in Libraries"
    ]
  },
  {
    "objectID": "llms.html",
    "href": "llms.html",
    "title": "Understanding Large Language Models",
    "section": "",
    "text": "Introduction\nThis Topic Guide, based on a Hack & Yack delivered as part of the British Library’s Digital Scholarship Training Programme, offers a brief introduction to Large Language models (LLMS) by way of ChatGPT, as a means of demystifying both quickly. Through hands-on activities and case studies, we’ll explore potential challenges and opportunities for the use of LLMs and ChatGPT in current and future library services.",
    "crumbs": [
      "Machine Learning and AI in Libraries",
      "Understanding Large Language Models"
    ]
  },
  {
    "objectID": "llms.html#introduction",
    "href": "llms.html#introduction",
    "title": "Understanding Large Language Models",
    "section": "",
    "text": "What are Large Language Models (LLMs)?\nA large language model (LLM) is a type of machine learning model that can perform natural language processing tasks such as generating and classifying text, answering questions, and translating text.\nIf your eyes just crossed reading that sentence, no wonder, there’s a lot of terminology and jargon to unpack there in that one little sentence. Let’s go back a few steps and take it a little slower!\nIt helps to first understand a little bit about what machine learning is. Machine learning (ML) is a core technology that underpins a lot of work in artificial intelligence work today. Artificial intelligence is actually a broad field that encompasses the development of systems and machines capable of performing tasks that typically require human intelligence, such as reasoning, problem-solving, learning, and perception, and…chatting!\nNatural Language Processing (NLP) is a specialised area within artificial intelligence (AI) that looks specifically at the challenges of processing and understanding human language (another is Computer Vision (CV) which is, on the other hand, concerned with helping computers process and understand imagery in the vein of human vision). NLP plays a vital role in enhancing the capabilities of AI systems by working to make them more capable of natural and effective interaction with humans.\nNLP involves the development of algorithms, models, and systems for analysing, understanding and extracting meaningful information from textual data representing human language. The field relies heavily on the use of machine learning to make sense of our complex textual data, which might come from literature, historical documents, articles, twitter, wikipedia, you name it!\nMachine learning involves the development of algorithms and models that allow computers to learn patterns and relationships from data and make predictions on new data. Instead of being explicitly programmed for specific tasks, ML algorithms use data to learn and improve their performance over time.\nA machine learning algorithm is designed to recognize patterns, relationships, and trends in data and will adjust their internal parameters based on examples to improve their performance over time.\nA machine learning model represents what was learned by a machine learning algorithm. The model that’s created in the process and saved after running a machine learning algorithm on training data and represents the rules, numbers, and any other algorithm-specific data structures required to make predictions on new data.\nSo back to our definition:\nA large language model (LLM) is a type of machine learning model that can perform natural language processing tasks such as generating and classifying text, answering questions, and translating text.\nLanguage models are a type of machine learning model designed to predict the likelihood of a sequence of text, which means that they can be set up to predict the most likely way to continue a conversation. The models behind ChatGPT are large, complex neural networks that have been exposed to an enormous amount of text from books, articles, websites, and more. These models have learned something about patterns in grammar and word meaning, including the way that meaning arises contextually across multiple sentences and multiple turns in a conversation. When you ask ChatGPT a question, you are presenting the model with new information it tries to make a prediction on, in this case, it tries to generate a response that matches the pattern of conversation. Large language models are trained on massive amounts of text data and are essentially the backbone of NLP today. There are and have been for many years, large language models out there actually but ChatGPT has currently caught the popular imagination because of its publicly available interface and remarkable performance.\n\n\nWhat is ChatGPT?\nChatGPT is a platform providing an interface specifically to the large language models developed by OpenAI. The GPT stands for Generative Pre-Trained Transformers which is just a fancy way of saying that the models you are chatting with have already been trained on a lot of data.\nIt's a chatbot essentially designed to generate human-like text responses based on the input it receives. Or some say to think of it as a fancy predictive text generator. You ask questions or give prompts, and it provides responses in natural language, or rather, estimates what should come next in a conversation.\n\nWhat ChatGPT is NOT:\n\nGoogle Search Box: Unlike Google, ChatGPT doesn't search the internet for information. Instead, it generates responses based on a massive dataset it was trained on. This training dataset includes large segments of text sampled from the internet at a specific point in time, and so can reflect language describing content on the internet, but it doesn't have real-time access to the internet. When ChatGPT answers a question, it isn’t actually looking up information and then composing that information into a response; it's just making an estimation of a response based on patterns it has seen. So, when you ask it factual questions, especially ones with common answers or phrases, it might give you an answer that sounds right but remember this is because it’s mimicking what it has seen in its training data. Think of it perhaps as a very smart parrot, sometimes 'repeating' things it has seen before.\nHuman Mind: ChatGPT is not a human; it's a machine learning model. It doesn't understand or reason like a human. It generates evidently linguistic responses based on patterns it learned from text data.\n\n\n\nHow ChatGPT Generates Responses:\n\nLanguage Modelling: So ChatGPT models are members of this class of models we’re talking about: “large language models” (LLMs). A machine learning model represents what was learned by a machine learning algorithm. The model is created and saved after running a machine learning algorithm on training data and represents the rules, numbers, and any other algorithm-specific data structures required to make predictions on new data. Language models are designed to predict the likelihood of a sequence of text, which means that they can be set up to predict the most likely way to continue a conversation. The models behind ChatGPT are large, complex neural networks that have been exposed to an enormous amount of text from books, articles, websites, and more. These models have learned something about patterns in grammar and word meaning, including the way that meaning arises contextually across multiple sentences and multiple turns in a conversation. When you ask ChatGPT a question, it tries to generate a response that matches these patterns.\nContextual Understanding: ChatGPT also looks at the context of the question you ask, including what’s happened so far in your conversation and any instructions or details you offer about how it should respond. It tries to understand the context and generate a response that is contextually relevant, which can make its answers seem quite accurate.\nExisting Knowledge: It can recall and blend information it has observed in its training data. So, when you ask a factual question, it can sometimes generate a response that seems factual because it has encountered similar information during training. But, it can also make mistakes or provide information that is outdated or biassed because it doesn't have the ability to verify the accuracy of what it says, and it is influenced by any views inherent in its training data, whether they are right or wrong. It's like the parrot repeating something it heard: it can't check if what it's saying is true or up-to-date. That's why it's important to double-check information output by ChatGPT with reliable sources, especially when using ChatGPT for research or critical tasks.\nUser Feedback Loop: ChatGPT models like the latest GPT-4 (openai.com) have been tuned and improved over time with user feedback, as part of a model training process known as “reinforcement learning”. So for example, when users request things like python code, and try it out, users provide feedback on whether or not it worked. This feedback helps the model get better at generating code that is more likely to work.\n\n\n\nWhen best to use ChatGPT:\n\nIdea Generation: ChatGPT can help brainstorm ideas for projects, essays, or creative endeavours. For example, you can ask it for ideas on new business ventures, book plots, or marketing campaigns.\nThesaurus and Rephrasing: It's excellent for finding synonyms, rephrasing sentences, or improving the clarity of your writing. You can ask it to provide alternative words or rewrite a paragraph for better readability.\nCreative Writing: ChatGPT can assist with creative writing tasks, including writing short stories, poems, or generating dialogues for characters.\nSome Learning and Explanation: It can provide explanations and answers to questions on a wide range of very general topics, making it useful for learning new concepts or understanding complex ideas. But again, always best to double check against other trusted resources.\nLanguage Translation: ChatGPT can offer some basic translation assistance, such as translating phrases or short sentences between languages.\nGenerating code snippets: It may not produce highly complex or critical code reliably but you can use it as a starting point for some common coding tasks.\n\n\n\nQuerying structured data: ChatGPT can provide outputs in the form of data structures including for instance SQL queries and JSON. So for instance if we have an SQL database with information about the content of a corpus, we can prompt ChatGPT to output queries that would apply to that database. We can then begin to imagine an interface where a non-expert user could make such a query using their own natural language, and ChatGPT could provide a connection with the structured data. This is sometimes referred to as “function calling” in the ChatGPT literature.",
    "crumbs": [
      "Machine Learning and AI in Libraries",
      "Understanding Large Language Models"
    ]
  },
  {
    "objectID": "llms.html#relevance-to-the-library-sector-large-language-models-llm-and-chatgpt-uses-in-libraries-today",
    "href": "llms.html#relevance-to-the-library-sector-large-language-models-llm-and-chatgpt-uses-in-libraries-today",
    "title": "Understanding Large Language Models",
    "section": "Relevance to the Library Sector: Large Language Models (LLM) and ChatGPT Uses in Libraries Today",
    "text": "Relevance to the Library Sector: Large Language Models (LLM) and ChatGPT Uses in Libraries Today\n[Need to work on this section with written examples/more narrative around opportunities and challenges]\n\nA Tech Librarian Explains How to Build AI Literacy - Choice 360\nChatGPT: Implications for academic libraries | Cox | College & Research Libraries News (acrl.org)\nUsing GPT on Library Collections (Matt Miller)\nhttps://programminghistorian.org/en/lessons/interrogating-national-narrative-gpt",
    "crumbs": [
      "Machine Learning and AI in Libraries",
      "Understanding Large Language Models"
    ]
  },
  {
    "objectID": "llms.html#hands-on-activity-and-other-self-guided-tutorials",
    "href": "llms.html#hands-on-activity-and-other-self-guided-tutorials",
    "title": "Understanding Large Language Models",
    "section": "Hands-on activity and other self-guided tutorial(s)",
    "text": "Hands-on activity and other self-guided tutorial(s)\nThe following activity was delivered to British Library staff as part of a monthly Hack & Yack.\n\nGetting started\nFor this activity we’ll primarily use the freely available ChatGPT (openai.com) interface. For this you’ll need to have a free google account.\n\n\nFirst, a word on writing prompts\nTo get a useful response from ChatGPT, “prompting” is key. If you only ask a simple question, you may not be happy with the results and decide to dismiss the technology too quickly, but today’s purpose is to have a deeper play in order to develop our critical thinking and information evaluation skills, allowing us to make informed decisions about utilising tools like ChatGPT in our endeavours.\nSome best practices for writing a good prompt (helpful hints/tips gleaned from the suggested readings in this guide):\n\nGive the context. The more you explain the ins and outs of what you want ChatGPT to do, the more relevant your answer will be. For example, “You are an expert in [fill in the blank for your topic].”\nBe very specific and concrete about what you want it to do (and equally, what you don’t want it to do). For instance you may want to specify word count, how many items you’d like in a list, tone of voice, etc.\nGive clear instructions on what the output should look like, and be simple and concise in your language.\nProvide examples. Much like a human, ChatGPT often understands best when you provide an example for it to work with, especially if you want it to produce something that closely resembles something you’ve seen online.\nAsk ChatGPT to “act like” someone: Sometimes, it can help to start your prompt by asking ChatGPT to “act like” a certain type of person that would be particularly well-placed to respond to the query you're posing.\n\nIf you’re not satisfied with any part of the answer, you can keep building on it, asking ChatGPT to revise it in any way you like as it will continue on from previous enquiries in a session. (If you’d rather it not do that you can add “Please ignore all previous instructions” to start a prompt fresh). To learn more about prompting, there is a free online course: Learn Prompting.\n\n\nExploratory activities:\n\nHave a play generating responses to some of the below questions (or come up with your own)!\nCritically evaluate the responses you receive from ChatGPT.\n\nIs the information/response credible?\nAre there any biases in the responses?\nDoes the information align with what you know from other sources?\n\nConsider your findings, the strengths and weaknesses, ethical considerations and challenges of using AI tools such as this.\n\n\n\n\nTry this….\n**Example Prompts\nFurther considerations/Notes\n\n\n\n\nAsk ChatGPT to create a title for a new exhibition\n\n\n\n\nAsk ChatGPT to create an exhibition label for items in an exhibition\n“Write an exhibition label for this archived website http://moorfootru nners.blogspot.co.uk/”\n\n\n\nAsk ChatGPT to create a blog post on a topic for which you are very familiar\n\n\n\n\nAsk ChatGPT to help you come up with ideas for teaching\nTry something like this:\n“You are an academic librarian focusing on instruction. Please make an outline of important topics to cover for a classroom lecture on ChatGPT. This will be part of a series of instruction sessions about information literacy. You have already worked with this class on the basic concepts of information literacy. Create the outline as a bulleted list and follow it with a classroom activity based on one of the topics you’ve discussed about ChatGPT.”\nFrom: A Tech Librarian Explains How to Build AI Literacy - Choice 36 0\nWhen you get the results, you can then ask it to give you an additional activity or set of activities on the same topic.\nHave a play around with different training subject areas.\n\n\nAsk ChatGPT to write a bio for yourself, providing it with details for instance as a list of facts about you\n\n\n\n\nAsk ChatGPT to Act as a Translator\nTry something like this:\n“I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is”istanbulu cok seviyom burada olmak cok guzel”\nFrom: Awesome ChatGPT Prompts | This repo includes ChatGPT prompt curation to use ChatGPT better. \n\n\n\nAsk ChatGPT to create an outline for a PowerPoint presentation\n\n\n\n\nAsk ChatGPT to extract metadata from a provided text\n\n\n\n\nAsk ChatGPT to write a query for a suppositional SQL database that you describe\n“We have an SQL database with the following tables: 'books' and 'authors'. The 'books' table has columns 'title', 'date', and 'topic'. The 'authors' table has columns 'name', 'birth_date', 'death_date', and 'gender'. I'm going to write some questions about things in this database, and I would like you to respond with SQL queries that would find the information I'm asking about.”\nRESPONSE: “Of course! Feel free to ask any questions you have about the database, and I'll provide you with SQL queries to retrieve the information you need. Please go ahead and ask your questions.”\nINPUT: “I'd like to find books about the second world war written by women born after the war ended.”\nRESPONSE: “To find books about the Second World War written by women born after the war ended, you can use the following SQL query:”\nSELECT b.title, b.date, a.name\nFROM books b\nJOIN authors a ON b.author_id = a.author_id\nWHERE b.topic = 'Second World War'\nAND YEAR(a.birth_date) &gt; 1945\nAND a.gender = 'female';\n\n\n\nHave a look at this project Matt Miller did experimenting with [Using GPT on Library Collections (thisismattmill er.com)]{.underlin e}\n“You are a helpful assistant that is summarizing and extracting data from a journal written by Susan B. Anthony in {RECORD_DATE_HERE}. You only answer using the text\ngiven to you. You do not make-up additional information, the answer has to be contained in the text provided to you. Each page is a diary entry or financial bookkeeping. You will structure your answer in valid JSON, if there are any quote marks in the content escape them as \".”\n“If the following text contains multiple journal entries, extract each one into an array of valid JSON dictionaries. Each dictionary represents one of the entries, extract the date and\nthe date again in the format yyyy-mm-dd and the city or state it was written in and other geographical locations mentioned that entry and people mentioned that entry and the complete\nfull text of the entry and a one sentence summary of the text, using the JSON keys dateText, dateFormated, cityOrState, geographicalLocations, people, fullText, summaryText: {FULL_TEXT_HERE}“\nThinking about this project, could you think of a similar collection that you might be able to experiment with to parse data similarly? How might you like to re-write the prompt for your own project?\n\n\nTry to use it to create social media posts\nThere is a new network called CHOSN for those working in Galleries-Libr aries-Archives-Museums (GLAM) and cultural heritage organisations as research support and research-active staff. This network is a community of practice for research support and research-active staff who work in GLAM organisations interested in developing and sharing open scholarship knowledge and skills, organising events, and supporting each other in this area. Can you write social media post for 140 character to announce this network and call people to join in?\n\n\n\nPROMPT: Act as a librarian advising a history student in the UK doing research into the third plague pandemic in India during the early 20th century. What archival resources could they use?\nRESPONSE: Certainly! If you're a history student in the UK researching the Third Plague Pandemic in India during the early 20th century, there are several archival resources you can explore to enhance your research. These archives will provide you with primary sources, documents, and historical records that can help you gain a deeper understanding of this important historical event. Here are some key archival resources to consider:\n1. **The National Archives (TNA) of the United Kingdom**:\n- TNA holds records related to British colonial administration in India during the early 20th century. Look for documents related to public health, sanitation, and official correspondence about the plague.\n2. **The India Office Records**:\n- These records are part of the British Library's holdings and contain a wealth of information on India during the colonial period. You can find reports, letters, and administrative documents related to the Third Plague Pandemic.\n3. **The British Library**:\n- The British Library has a substantial collection of materials related to India, including newspapers, periodicals, and publications from that era. You can find newspaper articles, books, and reports that discuss the plague's impact in India.\n4. **The Wellcome Collection**:\n- The Wellcome Collection in London has an extensive library and archive of materials related to the history of medicine. You may find documents, photographs, and medical reports pertaining to the plague in India.\n5. **Local Archives in India**:\n- Depending on your specific focus within India, you should also explore local archives and libraries. For example, the National Archives of India in Delhi and state archives may have valuable records.\n6. **Digital Collections**:\n- Many institutions, including the British Library and the Wellcome Collection, have digitized collections that you can access online. These digital resources can be very helpful for remote research.\n7. **University Libraries**:\n- Don't forget to check with your university's library. They may have subscriptions to digital archives and databases that can provide access to primary source materials and scholarly articles related to the Third Plague Pandemic in India.\n8. **Academic Journals**:\n- Look for scholarly articles in history and medical history journals. JSTOR and other academic databases can be valuable for finding secondary sources and research papers.\n9. **Interlibrary Loan Services**:\n- If you find a source or book that's not available in your university's library, you can request it through interlibrary loan services. This expands your access to materials from other institutions.\n10. **Archival Finding Aids**:\n- Be sure to use finding aids and catalog search tools provided by these institutions to locate specific documents and records related to the Third Plague Pandemic.\nRemember to take thorough notes, document your sources meticulously, and consult with your professors or advisors for guidance throughout your research process. Good luck with your research into this important historical topic!\n\n\n\nPROMPT: Act as an archivist producing a catalogue record for an archival document. What subject, place and name authorities or terms would you choose for the following text? [gave it c50% of the full text transcription of IO R/F/4/1754/71645]\nRESPONSE: Here's a suggested catalog record for the provided archival document, along with subject, place, and name authorities/terms:\nTitle: Development of Hemp Cultivation for Cordage Manufacturing\nAuthor: [Author's Name if available]\nDate: [Date of the Document, if available]\nDescription:\nThis archival document explores the historical development of hemp cultivation for cordage (rope) production, emphasizing its critical importance for mechanical purposes and ship rigging during the 19th century. It discusses the transition from skin and leather ropes to vegetable fiber, particularly hemp, and the widespread cultivation and commerce of hemp in various nations. The document highlights the vital role of hemp during wartime and its impact on British shipping during supply disruptions. Additionally, it underscores the attention given to hemp cultivation in India and its various applications, focusing on the Cannabis Sativa plant.\nSubjects:\nCordage Industry\nHemp Cultivation\nRope Manufacturing\nShip Rigging\nHemp Fiber\nAgriculture in India\nColonial Agriculture\nInternational Commerce\nWar Supply Chains\nMechanical Engineering\nFiber Plants\nPlaces:\nUnited Kingdom\nIndia\nNorth America\nRussia\nArabia\nPersia\nChina\nEgypt\nTurkey\nEurope\nAsia\nNames:\nAlexandre Yersin (if mentioned as the author or contributor)\nDr. Roxburgh (for his contributions to hemp cultivation in India)\nNotes:\nThis document provides historical insights into the cultivation of hemp for cordage and its significance in various regions during the 19th century, with a focus on its mechanical properties and wartime importance.\nPlease note that the specific author and date of the document were not provided in the text you provided. If this information is available, it should be included in the catalog record. Additionally, you may need to consult relevant authority files or controlled vocabularies to ensure accuracy in subject, place, and name authorities.\nCOMMENT: The inclusion of Yersin as a suggested authority is interesting / worrying, as he had cropped up in an answer to a previous question, and I had told it to disregard all of the previous conversation data before posting the cataloguing prompt…\nIn terms of indexing, it included a lot of incidental references in the text which a cataloguer would not include as subject or place index terms [should flag at this point that I did not write the BL’s catalogue entry for this]]\nI should really give it the full text before judging the description…",
    "crumbs": [
      "Machine Learning and AI in Libraries",
      "Understanding Large Language Models"
    ]
  },
  {
    "objectID": "llms.html#recommended-reading-viewing",
    "href": "llms.html#recommended-reading-viewing",
    "title": "Understanding Large Language Models",
    "section": "Recommended Reading & Viewing",
    "text": "Recommended Reading & Viewing\n\n40 Best ChatGPT Prompts You Simply Have To Try in 2023 (tech.co)\nA Tech Librarian Explains How to Build AI Literacy - Choice 360\nChatGPT: Implications for academic libraries | Cox | College & Research Libraries News (acrl.org)\nUsing GPT on Library Collections (Matt Miller)\nhttps://programminghistorian.org/en/lessons/interrogating-national-narrative-gpt\nWelcome | Learn Prompting: Your Guide to Communicating with AI",
    "crumbs": [
      "Machine Learning and AI in Libraries",
      "Understanding Large Language Models"
    ]
  },
  {
    "objectID": "llms.html#taking-the-next-steps",
    "href": "llms.html#taking-the-next-steps",
    "title": "Understanding Large Language Models",
    "section": "Taking the next steps",
    "text": "Taking the next steps",
    "crumbs": [
      "Machine Learning and AI in Libraries",
      "Understanding Large Language Models"
    ]
  },
  {
    "objectID": "iiif.html",
    "href": "iiif.html",
    "title": "IIIF",
    "section": "",
    "text": "Introduction\nsdfajsdhflakjhfalkejrhf",
    "crumbs": [
      "IIIF"
    ]
  },
  {
    "objectID": "iiif.html#relevance-to-the-library-sector",
    "href": "iiif.html#relevance-to-the-library-sector",
    "title": "IIIF",
    "section": "Relevance to the Library Sector",
    "text": "Relevance to the Library Sector\nwerw4rwerw34rw",
    "crumbs": [
      "IIIF"
    ]
  },
  {
    "objectID": "iiif.html#hands-on-activities-self-guided-tutorials",
    "href": "iiif.html#hands-on-activities-self-guided-tutorials",
    "title": "IIIF",
    "section": "Hands-On Activities & Self-Guided Tutorials",
    "text": "Hands-On Activities & Self-Guided Tutorials\ndfgdfgdfgdfg",
    "crumbs": [
      "IIIF"
    ]
  },
  {
    "objectID": "iiif.html#recommended-reading-further-reading",
    "href": "iiif.html#recommended-reading-further-reading",
    "title": "IIIF",
    "section": "Recommended Reading & Further Reading",
    "text": "Recommended Reading & Further Reading\n34hjdhfbkajdhbgksjehrger",
    "crumbs": [
      "IIIF"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Recommended Reading Lists",
    "section": "",
    "text": "There is no shortage of recommended reading lists out there, here we try and highlight a few of the most up to date and useful lists out there for the sector today!\nZotero Library for Digital Scholarship and Data Science Essentials for Library Professionals\nThis library contains links to all of the resources referenced within Topic Guides and across our site.\nZotero | Groups &gt; collections as data - projects, initiatives, readings, tools, datasets\nOngoing collection of projects, readings, initiatives, tools, and datasets that are in some way or another related to collections as data. This group is an open resource, welcoming contributions from anyone who has a resource to share.\n[TODO] Data Science in Libraries, is there a Zotero?",
    "crumbs": [
      "**GENERAL RESOURCES**",
      "Recommended Reading Lists"
    ]
  },
  {
    "objectID": "reports.html",
    "href": "reports.html",
    "title": "Skills Competency Frameworks & Key Reports",
    "section": "",
    "text": "The following are Skills Competency Frameworks & Key Reports relating to supporting Digital Scholarship and Data Science for library staff\n\nLIBER Publications\n\nLIBER Digital Skills for Library Staff & Researchers Working Group - LIBER Europe have lots of resources here, including a very useful diagram Identifying Open Science Skills for Library Staff & Researchers\nLIBER Job Description Repository Contains job description examples for Digital Curator and other digital roles which reference the types of skills required for such work.\nEurope’s Digital Humanities Landscape: A Study From LIBER’s Digital Humanities & Digital Cultural Heritage Working Group is a report based on a Europe-wide survey run by LIBER’s Digital Humanities & Digital Cultural Heritage Working Group. The survey focused on digital collections and the activities libraries undertake around them. It covered the following topics and themes including staffing/skills\n\n\n\nKey Publications specific to digital scholarship and data science skills for research library staff\n\nThe British Library and the Arts and Humanities Research Council published a report on skills: Scoping Skills and Developing Training Programme for Managing Repository Services in Cultural Heritage Organisations. There is a very useful section (Section 3.) that references several other digital skills frameworks for research library staff across Europe.\nLippincott, Joan K. Directions in Digital Scholarship: Support for Digital, Data-Intensive, and Computational Research in Academic Libraries. Coalition for Networked Information, June 2023. https://doi.org/10.56561/ULHJ1168\nPadilla, Thomas. ‘Responsible Operations: Data Science, Machine Learning, and AI in Libraries’. OCLC, 26 August 2020. https://www.oclc.org/research/publications/2019/oclcresearch-responsible-operations-data-science-machine-learning-ai.html.\nCordell, R. C. (2020). Machine Learning + Libraries: A Report on the State of the Field. LC Labs, Library of Congress. https://labs.loc.gov/static/labs/work/reports/Cordell-LOC-ML-report.pdf\nFederer L. Defining data librarianship: a survey of competencies, skills, and training. J Med Libr Assoc. 2018 Jul;106(3):294-303. doi: 10.5195/jmla.2018.306. Epub 2018 Jul 1. PMID: 29962907; PMCID: PMC6013124.\n\n\n\nGeneral Competencies for Librarians which include reference to digital\n\nAmerican Library Association (ALA) Library Competencies (Various roles): Library Competencies | Tools, Publications & Resources (ala.org) (USA)\nCanadian Association of Research Libraries Competencies for Librarians in Canadian Research Libraries Publications and Documents (including specifically Competencies-Final-EN-1-2.pdf (Canada)\nCILIP: the library and information association Professional Knowledge & Skills Base - (UK)",
    "crumbs": [
      "**GENERAL RESOURCES**",
      "Skills Competency Frameworks & Key Reports"
    ]
  },
  {
    "objectID": "training-platforms.html",
    "href": "training-platforms.html",
    "title": "Training Platforms",
    "section": "",
    "text": "When you’re ready to go further and have a better idea of the specific skills you need for a particular task, we can recommend having a good search through these excellent platforms which host a great many in-depth training materials:\n\nDARIAH-Campus\nDARIAH is a pan-European infrastructure for arts and humanities scholars working with computational methods. It supports digital research as well as the teaching of digital research methods. Though not specific to the library professional context, tutorials here are useful for applying techniques to digital collections. https://campus.dariah.eu/\n\n\nThe Glam Workbench\nThe GLAM Workbench is the brainchild of Tim Sherratt, a historian, and is a collection of Jupyter notebooks to help you explore and use data from GLAM institutions (galleries, libraries, archives, and museums). It includes tools, tutorials, examples, hacks, and even some pre-harvested datasets. It’s aimed at researchers in the humanities but has useful tutorials for anyone interested in working with GLAM data. https://glam-workbench.net/\n\n\nIneo\nIneo is a project developed and maintained by CLARIAH that lets you search, browse, find and select digital resources for research in humanities and social sciences. At the end of 2024 it will offer access to thousands of tools, datasets, workflows, standards and learning material. It is a work in progress so do keep that in mind when browsing. https://www.ineo.tools/\n\n\nLibrary Carpentry\nLibrary Carpentry is an international volunteer community, under the Carpentries, focussed building software and data skills within library and information-related communities. The lessons here are meant to be taught as workshops led by a Carpentries certified instructor (for a fee) but you may find it useful to have a read through the content which is open and available to all. https://librarycarpentry.org/\n\n\nThe Programming Historian\nThe Programming Historian has been publishing peer-reviewed tutorials on digital tools and techniques for humanists since 2008 and though they’re generally aimed at academic researchers, staff at British Library have found them highly useful over the years in their own work! https://programminghistorian.org/en/",
    "crumbs": [
      "**GENERAL RESOURCES**",
      "Training Platforms"
    ]
  },
  {
    "objectID": "networks.html",
    "href": "networks.html",
    "title": "Useful Networks",
    "section": "",
    "text": "LIBER Working Groups\nWorking groups are open to staff at participating LIBER Member institutions: - LIBER Data Science in Libraries - LIBER Digital Scholarship & Digital Cultural Heritage - Or have a look at the other LIBER Working Groups - LIBER Europe",
    "crumbs": [
      "**GENERAL RESOURCES**",
      "Useful Networks"
    ]
  },
  {
    "objectID": "networks.html#international-networks",
    "href": "networks.html#international-networks",
    "title": "Useful Networks",
    "section": "International Networks",
    "text": "International Networks\n\nAI4LAM\nCode4Lib\nElectronic Literature Organisation\nFlickr Commons\nGlam Labs International\nIIIF/UV Open Collective\nIMPACT Centre of Competence\nMuseums Computer Group\nTranskribus\nWikidata Community)",
    "crumbs": [
      "**GENERAL RESOURCES**",
      "Useful Networks"
    ]
  },
  {
    "objectID": "networks.html#national-networks-european",
    "href": "networks.html#national-networks-european",
    "title": "Useful Networks",
    "section": "National Networks (European)",
    "text": "National Networks (European)\n\nIreland/UK\n\nRLUK Digital Scholarship Network",
    "crumbs": [
      "**GENERAL RESOURCES**",
      "Useful Networks"
    ]
  },
  {
    "objectID": "project-overview.html",
    "href": "project-overview.html",
    "title": "Project Overview",
    "section": "",
    "text": "Core Project Team\nThe site and content are maintained by the Co-Chairs and select Members of the collaborating WGs listed here who act as the core project delivery team and editors of this resource.\nJodie Double, Editor DSDCH\nPéter Király, Editor DSLib\nNora McGregor, Editor DSDCH\nNeha Moopen, Site Maintainer DSLib\nPeter Verhaar, Editor DSLib",
    "crumbs": [
      "**ABOUT**",
      "Project Overview"
    ]
  },
  {
    "objectID": "project-overview.html#community-contributors",
    "href": "project-overview.html#community-contributors",
    "title": "Project Overview",
    "section": "Community Contributors",
    "text": "Community Contributors\nEach Topic Guide is written by specific named contributors but we also welcome changes and contributions to this resource via logging issues or if you’re a more seasoned GitHub user, via pull requests to the github repository. A full list of contributors will be compiled here once the first edition is complete.",
    "crumbs": [
      "**ABOUT**",
      "Project Overview"
    ]
  },
  {
    "objectID": "project-overview.html#acknowledgements",
    "href": "project-overview.html#acknowledgements",
    "title": "Project Overview",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThe project team would like to thank all of our LIBER working group members who have contributed to this resource and supported our endeavours here. We have taken great inspiration from other incredible training initiatives such as the British Library Digital Scholarship Training Programme, DH Literacy Guidebook and The Programming Historian in the development of this resource and thank those projects for paving the way!",
    "crumbs": [
      "**ABOUT**",
      "Project Overview"
    ]
  },
  {
    "objectID": "contributing.html",
    "href": "contributing.html",
    "title": "Contribute to our Project",
    "section": "",
    "text": "Ways to contribute to this project",
    "crumbs": [
      "**ABOUT**",
      "Contribute to our Project"
    ]
  },
  {
    "objectID": "contributing.html#ways-to-contribute-to-this-project",
    "href": "contributing.html#ways-to-contribute-to-this-project",
    "title": "Contribute to our Project",
    "section": "",
    "text": "Write a new Topic Guide\nContribute to an existing Topic Guide or Additional Resources by opening an issue or adding to existing ones on Github\nPropose a new Topic Guide by starting a discussion on GitHub\nJoin one of the LIBER Working Groups Digital Scholarship and Digital Cultural Heritage Collections or Data Science in Libraries (open to all staff of LIBER member institutions)",
    "crumbs": [
      "**ABOUT**",
      "Contribute to our Project"
    ]
  },
  {
    "objectID": "contributing.html#writing-a-new-topic-guide",
    "href": "contributing.html#writing-a-new-topic-guide",
    "title": "Contribute to our Project",
    "section": "1. Writing a new Topic Guide",
    "text": "1. Writing a new Topic Guide\n\nThese guidelines are written specifically for attendees wishing to contribute to the writing of Topic Guides on our wishlist as part of the Topic Guide Sprint being held on Tue May 14, 2024 9am - 11am (BST). If you would like to take part please contact digitalresearch@bl.uk to be sent the meeting calendar invite.\n\n\nPlease have a quick read through the Welcome and Topic Guide pages to familiarise yourself with this resource and its purpose.\nHave a look at our Topic Guide wishlist beforehand and put your name against existing topics you’re available to work on.\nPlease familiarise yourself with the Contribution Guidance and Style Guide section below\nFind the Topic Guide Template (Google Doc) that corresponds to your topic of choice in this folder and get writing!\nAt the end of the sprint, open an Issue in Github using the Issue Template to let us know what the status is of your Topic Guide (for example is it ready to be reviewed/published or does more need doing after the sprint).\nWhen you are ready to submit, either at the end of the workshop or later on, please follow the directions under “Submission Guidelines-For Contributors”\n\n\nGuidance and Style Guide\nEach Topic Guide must include a Header Section composing of a title, contributor information, and suggested citation. This is followed by five key content blocks detailed below. Please have a look at the IIIF Guide as an example of how these pieces all fit together into one complete Topic Guide.\n\nHeader Section\n\nTopic Guide Title: IIIF\nContributor(s) Name & (Orcid ID): Nora McGregor (ORCID iD)\nSuggested Citation: Nora McGregor, “IIIF,” Digital Scholarship & Data Science Essentials for Library Professionals (2024), [DOI link]\n\nNote: The project team will ensure each Topic Guide is given an individual DOI either through British Library or Zenodo.\n\n\nContent Blocks\n\nI: Introduction to the topic (Approximately 300-500 words)\nThis introduction section should be pitched at a beginner/foundational level and gives a concise overview of the topic. It should be written in a relaxed and natural way.\n\nImagine that a colleague has come to you casually asking about the topic over tea. How might you go about explaining it to them in your own words? During the course of that casual conversation what key things would you leave in and what might you leave out in the interest of getting them to a basic understanding quickly?\n\nThis section does not need to contain the world’s knowledge, just enough high-level knowledge to get the key concepts across. Linking can be used liberally for jargon busting throughout if explaining a particular term is more complex than our word count allows.\n\n\nII: Relevance to the Library Sector (Approximately 300-500 words)\nThis section provides a clear explanation of the topics’ specific relevance to the work of libraries.\nIt should contain:\n\nA short paragraph or two setting the scene as to why the topic is relevant to the work of libraries. Here you might also like to present opportunities and, if relevant, potential challenges for libraries around the topic as well.\n1- 3 examples of real world (or potential) applications/case studies/projects briefly explained in a 100 max word summary provided each with links to further information if available. Note that it is not necessary to write up or create a new case study yourself here! Rather, we’re looking for briefly summarised references to existing ones. If there are quite a few other examples the contributor would like to reference include, links to these can be added at the end of this section (Example: “For further case studies, visit….”).\n\n\n\nIII: Hands-on activity and other self-guided tutorial(s)\nThe objective of this section of the topic guide is to enable learners to familiarise themselves with the basics of the topic via self-paced tutorials and hand-on activities. The aim of this section, in other words, is to provide selected links to online learning materials which have proven valuable and can be personally recommended for library professionals.\nThe tutorials listed in this section should be suitable for independent study, and they should consist of detailed explanations of the steps learners can follow to develop the needed competencies. They may consist of textual explanations or of video recordings, and they may be in any European language.\nFor the sake of consistency across the various topic guides, it is helpful if these paragraphs are structured as follows:\n\nThe opening sentence should state the name of the resource, the URL (added as a hyperlink), and citation information, preferably in BibTex format\nThe remainder of the paragraph might then explain why the Topic Guide author recommends the tutorials, an explanation of the relevance or the value of the tutorial, and, optionally, an indication of topics covered and the level of complexity.\nThe paragraph should conclude with a short discussion of the exercises that are provided in the tutorial. For instance, add a personal touch as to why you are personally recommending this particular tutorial. Each tutorial reference paragraph should contain no more than 200 words.\n\nIn addition to such pointers to existing tutorials, authors of topic guides may also discuss exercises or other hand-on activities that may help to develop an understanding of the topic at hand. Such suggestions for hands-on activities may take various forms, and these guidelines do not prescribe a strict format. Authors may choose to include a practical exercise, a link to a well-documented github repository, or a link to a GLAM workbench.\n\n\nIV: Recommended Reading & Viewing\nThe section on recommended reading and viewing contains references to more passive learning resources such as:\n\nOpen access articles discussing the topic at a general level, or containing contextual information.\nVideo recordings of lectures about the topic, which do not demand practical activities from the viewer Podcasts about the topic\n\n[ # TODO: How should authors link to publications? Instruction here on how to use the Zotero Library?]\n\n\nV: Taking the next steps\nThis section provides guidance to library professionals on where to take their learning journey further. It should include:\n\nWhere to find (local/national/international) Communities of Practice or other relevant networks and organisations who can help with furthering their understanding of the topic.\nIf relevant you might also point to specific summer school courses, conferences and events that may further enhance learning.\n\n\n\n\n\nSubmitting your Topic Guide\nDuring the workshop, you’ve been working on your Topic Guide in a Google Doc. This Google Doc can continue to serve as a ‘living document’ following the workshop until you feel the content is ready to be published to Digital Scholarship and Data Science Essentials for Library Professionals. Throughout this process, we would like to maintain an overview of the docs in terms of their status and action points using the functionality offered by GitHub Issues.\nAt the end of the sprint therefore, we will ask you to head over to GitHub and open an ‘Issue’ to start a submission of your Topic Guide. We will provide an issue template which is pre-formatted as a submission checklist. Please go through the issue template and provide the necessary information relating to where the submission is currently at. Once the issue is saved, it can continue to serve as a space to continue discussion of the ongoing status of your submission and log updates where necessary, including notifying us of when it is fully ready for final review by maintainers.\nThings to note when creating an Issue for your newly created Topic Guide under development: - If you want to include resources such as images and videos etc. which cannot be linked to via the web - you might have to provide the files themselves to us. You can attach any local files as a comment on the Issue you have created for your Topic Guide. - Any references used should also be added to the Zotero library and/or provided in BibTex format. - You may request placing your Google Doc under restricted access if you wish. We will not do this by default, but we respect that some contributors would like to keep drafts private until fully ready for submission.\nWhen your Topic Guide is ready for our review in Google Docs, please let us know by logging an update over on Github as a comment on the issue stating this. You can also tag the maintainers so they receive a notification as well. Maintainers will generally work with you on the final edits necessary for the submission through track changes and comments within the Google Doc itself. Once these have all been resolved maintainers will log a status update indicating “Review complete; Final Submission Ready; Make live” in the GitHub issue.",
    "crumbs": [
      "**ABOUT**",
      "Contribute to our Project"
    ]
  },
  {
    "objectID": "updates.html",
    "href": "updates.html",
    "title": "Ongoing Maintenance and Content Review",
    "section": "",
    "text": "Throughout 2023/2024 we are working on producing the first complete edition of this resource for launch at the LIBER Annual Conference 3-5 July 2024. That edition will be deposited in the British Library Research Repository, captured in the UK Web Archive, and a DOI provided. Topic Guides are currently being produced by direct invitation, as well as through a series of in-person and online writing sprints of working group members.\nThe first edition Topic Guide list draws heavily on the existing skills framework and topics covered in the British Library’s Digital Scholarship Training Programme, as well as those recommended by attendees of development workshops hosted by LIBER working groups throughout 2023.\nWe view this resource as capturing a snapshot in time and will endeavour to fully review all content a minimum of once annually to check for link rot, and content relevancy. The project team editors are committed to make quick fixes when raised throughout the year, while formal sprints and reviews coinciding with LIBER Annual Summer Conference and Winter events will be used for soliciting new content and undertaking more complex updates to the resource each year.",
    "crumbs": [
      "**ABOUT**",
      "Ongoing Maintenance and Content Review"
    ]
  },
  {
    "objectID": "licensing.html",
    "href": "licensing.html",
    "title": "Licensing & Re-use",
    "section": "",
    "text": "Citing this Resource\nSuggested citations are written in APA (American Psychological Association) citation style for Journal Articles and are given on each individual guide:\nMcGregor, Nora, “IIIF,” Digital Scholarship & Data Science Essentials for Library Professionals (2024), [DOI link]\nTo cite the full resource:\nMcGregor, N., Verhaar, P., Moopen, N., Double, J., Irollo, A., & Kiraly, P. (Eds.). (2024, March 12). Digital Scholarship & Data Science Essentials for Library Professionals. https://libereurope.github.io/ds-essentials",
    "crumbs": [
      "**ABOUT**",
      "Licensing & Re-use"
    ]
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "If you’d like to ask a question of the project team you can please send an email to Nora McGregor, nora.mcgregor@bl.uk or any of Co-Chairs and select Members of the collaborating WGs listed here who act as the core project delivery team and editors of this resource.\nJodie Double, Editor DSDCH\nPéter Király, Editor DSLib\nNora McGregor, Editor DSDCH\nNeha Moopen, Site Maintainer DSLib\nPeter Verhaar, Editor DSLib",
    "crumbs": [
      "**ABOUT**",
      "Contact"
    ]
  }
]