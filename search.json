[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Digital Scholarship & Data Science Essentials for Library Professionals",
    "section": "",
    "text": "Welcome\nDigital Scholarship and Data Science Essentials for Library Professionals is an open and collaboratively curated training reference resource. It aims to make it easier for LIBER library professionals to gain a concise overview of the new technologies that underpin digital scholarship and data science practice in research libraries today, and find trusted training materials recommendations to start their professional learning journey.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#our-aims",
    "href": "index.html#our-aims",
    "title": "Digital Scholarship & Data Science Essentials for Library Professionals",
    "section": "Our Aims",
    "text": "Our Aims",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#who-is-it-for",
    "href": "index.html#who-is-it-for",
    "title": "Digital Scholarship & Data Science Essentials for Library Professionals",
    "section": "Who is it for?",
    "text": "Who is it for?\nAre you someone working in or around research libraries with an interest in learning more about how to do cool and interesting things with digital collections and data at your institution? Wondering how data science techniques can help you in your work? Are you interested in gaining valuable digital literacy skills and knowledge to support emerging areas of modern scholarship such as Digital Humanities? Do you need some of the technology jargon you hear about these days demystified?\nThen this resource is for you!\nIt is very important to us that this resource is inclusive and intellectually accessible, challenging but not terrifying and as such we focus primarily on an introductory audience where no programming or particular digital skills are required.\nThough written primarily from the research library professional perspective these guides will be useful for anyone currently (or aspiring to be) working in and around digital collections and data in heritage institutions:\n\nLibrary & Information Science students\nProject managers\nDevelopers\nInformation specialists\nMetadata Managers\nSubject librarians\nSystem librarians\nInstitutional leadership\n\nAnd so many more!",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#why-this-resource",
    "href": "index.html#why-this-resource",
    "title": "Digital Scholarship & Data Science Essentials for Library Professionals",
    "section": "Why this resource?",
    "text": "Why this resource?\nOver the past few decades, the development of excellent self-paced tutorials and training materials relating to undertaking digital scholarship and data science in libraries have proliferated online.\nFor library professionals who are relatively new to this area however, it can be hard to know where to begin! Without knowing a little bit about the context of how new technologies are being deployed in research libraries, this dearth of resources can seem quite daunting. Even if you might have an idea of what learning you’d like to undertake, it can be difficult and time consuming to try and navigate the wealth of individual training resources out there on your own.\nDigital Scholarship and Data Science Essentials for Library Professionals is a training reference resource we have developed to remove some of the barrier of having to hunt for recommended training and resources to get you on the learning ladder.\nFrom working with data, data management, digital storytelling, handwritten recognition technologies and more, our Topic Guides provide contextualised and gentle introductions, written from the library practitioners perspective, to a wide range of key topics and technologies relevant to working innovatively with our digital collections and data.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#what-are-topic-guides",
    "href": "index.html#what-are-topic-guides",
    "title": "Digital Scholarship & Data Science Essentials for Library Professionals",
    "section": "What are Topic Guides?",
    "text": "What are Topic Guides?\nTopic Guides are the heart and soul of Digital Scholarship and Data Science Essentials for Library Professionals. The aim of each is to provide research library professionals with a gentle and concise introduction to the key topics in this area today. They offer those with no prior knowledge, quick and curated guidance to personally recommended hands-on tutorials, use-cases, articles, videos, networks and communities of practice to deepen learning.\nEach Topic Guide follows a fixed structure, consisting of five components in order to make it easier to quickly find what you might need:\n\nIntroduction to the topic\nRelevance to the library sector (Case studies/Use cases)\nHands-on activities and other self-guided tutorial(s)\nRecommended Reading & Viewing\nTaking the next steps (Communities of Practice)",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#how-to-use-this-resource",
    "href": "index.html#how-to-use-this-resource",
    "title": "Digital Scholarship & Data Science Essentials for Library Professionals",
    "section": "How to use this resource",
    "text": "How to use this resource\nThis resource has a dual purpose; it is written as a tool for self-study but also as a guide for individuals and institutions interested in establishing their own local training programmes.\nAs a self-study resource, we hope it can serve as a useful first point of entry into complex topics in digital scholarship and data science and their application in the library world. It is not meant to be completed in any particular order, rather, learners are invited to jump in and out of individual topic guides as personal curiosity or practical need dictates.\nThe materials here can also be utilised in group study, as part of a reading group or even a hands-on Hack & Yack. See our special section on “How to start your own training programme” for some tips and tricks from British Library Digital Research Team colleagues on utilising the materials referenced here at your own library or within your network.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "topicguides.html",
    "href": "topicguides.html",
    "title": "TOPIC GUIDES",
    "section": "",
    "text": "Topic Guides are the heart and soul of Digital Scholarship and Data Science Essentials for Library Professionals. The aim of each is to provide research library professionals with a gentle and concise introduction to the key topics in this area today. They offer those with no prior knowledge, quick and curated guidance to personally recommended hands-on tutorials, use-cases, articles, videos, networks and communities of practice to deepen learning.\nEach Topic Guide follows a fixed structure, consisting of a descriptive header and five key components in order to make it easier to quickly find the information you might need:\n\nIntroduction to the topic\nRelevance to the library sector (case studies/use cases)\nHands-on activities and other self-guided tutorial(s)\nRecommended reading & viewing\nTaking the next steps (finding Communities of Practice)\n\nThe guides are not presented, nor meant to be completed, in any particular order, rather, you are invited to jump in and out of individual topics as personal curiosity or practical need dictates.\nThe Topic Guide list in this first edition draws heavily on the existing skills framework and topics covered in the British Library’s Digital Scholarship Training Programme, as well as those recommended by attendees of a series of development workshops held with LIBER working groups throughout 2023.\nOur current wishlist includes but is not limited to topics such as:\n\n2D/3D Imaging: 3D Modelling and RTI\nAutomatic Text Transcription (OCR/HTR)\nDemystifying Computational Environments for Digital Scholarship\nClimate Change and Sustainability\nCollections as Data\nCopyright and Licensing\nCrowdsourcing & Citizen Science in the cultural heritage context\nComputer Vision\nCultural Competency & Ethics\nData Visualisation\nDigital Mapping\nDigital Scholarship Project Management, Evaluation and Assessment\nDigital Storytelling\nGetting started in programming\nGithub and GitPages/Quarto\nIIIF\nLinked Open Data\nMachine Learning and AI in Libraries Literacies\nOpen Research\nResearch Data Management\nWhat is an API?\nWikimedia\nWorking with Data",
    "crumbs": [
      "**TOPIC GUIDES**"
    ]
  },
  {
    "objectID": "ml-ai.html",
    "href": "ml-ai.html",
    "title": "AI and Machine Learning in Libraries",
    "section": "",
    "text": "Introduction\nAI is mentioned absolutely everywhere these days, in movies, in the news, in our library strategies and our funding calls, but what does it really mean and is anyone even using it correctly? Let’s try to get to the bottom of this!\nArtificial Intelligence (AI) is actually a really broad field of computer science (and an umbrella term) that refers to the research and development of systems and machines capable of doing tasks that typically require human intelligence to perform, such as reasoning, problem-solving, learning, and perception. Sometimes folks may speak of and refer to AI as systems and machines that actually having true intelligence, and though todays AI systems are shockingly convincing in how well they perform, what we’re seeing today are just very advanced machine learning algorithms and models performing specific and discrete functions extremely well! We’re a long way off (if ever) from machines having sentience (or, Generalised Artificial Intelligence (GAI), so don’t worry!\nWhenever AI is being discussed you may often hear the term machine learning mentioned, and sometimes they’re used interchangeably which can be confusing. Machine learning is more specifically a core technology that is itself a main subfield of AI, and also underpins other subfields of AI like Natural Language Processing (NLP), Computer Vision (CV), and Generative AI.\nThese days, AI has been further grouped into Traditional AI and Generative AI. Traditional AI refers to machine learning based systems like (NLP and CV) for doing tasks like classifying data (e.g., assigning labels to images, automatically transcribing handwritten texts, or identifying genre of digitised texts). This is the type of AI we make a whole lot of use of in the library world. Generative AI on the other hand refers broadly to systems whose primary function is to generate new content (e.g., conversation, books, art). This is where conversational AI systems like ChatGPT (Generative Pre-trained Transformer) fall under for example and we’re only just now exploring the potential applications for these new powerful Generative AI systems in library work.\nMachine learning (ML), again both itself a subfield of AI and a technology that underpins other fields of AI, focuses on the development of algorithms and models that allow computers to learn patterns and relationships from data and make predictions on new data. Instead of being explicitly programmed for specific tasks, ML algorithms use data to learn and improve their performance over time.\nA machine learning algorithm is designed to recognize patterns, relationships, and trends in data, and they adjust their internal parameters based on examples to improve their performance over time. Machine learning algorithms play a crucial role in various applications.\nA machine learning model represents what was learned by a machine learning algorithm. The model is created and saved after running a machine learning algorithm on training data. The model represents the rules, numbers, and any other algorithm-specific data structures required to make predictions on new data.\nIn the next section we’ll consider one particularly common use case in order to walk us more practically through the concept of how machine learning works: automatic transcription of handwritten text.",
    "crumbs": [
      "AI and Machine Learning in Libraries"
    ]
  },
  {
    "objectID": "ml-ai.html#introduction",
    "href": "ml-ai.html#introduction",
    "title": "AI and Machine Learning in Libraries",
    "section": "",
    "text": "But first, a quick quiz!\nWhich of the following do you think would use Machine Learning?\n\nCounting the number of people in a museum using information from entry and exit barriers.\nA search system that looks for images similar to a user submitted sketch.\nA system that recommends library books based on what other users have ordered.\nA queueing system that spreads people evenly between 5 ticket booths\nA program which extracts names from documents by finding all capitalised words and checking them against a list of known names\nA system which turns digitised handwritten documents into searchable text\nA robot that cleans the vases in a museum without bumping into them or breaking them\n\nIf you answered 2, 3, 6 & 7 you are correct! The others could all be easily programmed using a simple set of easily defined rules, rather than requiring prediction.",
    "crumbs": [
      "AI and Machine Learning in Libraries"
    ]
  },
  {
    "objectID": "ml-ai.html#relevance-to-the-library-sector",
    "href": "ml-ai.html#relevance-to-the-library-sector",
    "title": "AI and Machine Learning in Libraries",
    "section": "Relevance to the Library Sector",
    "text": "Relevance to the Library Sector\nCover NLP and Computer Vision here and include Transkribus case study as an example of how models and algorithms work.\n\nLet’s say you have 20,000 pages of handwritten manuscripts that you would like to transcribe and turn into machine readable text to allow for better search for your researchers. A task of this scale would be far too for any one, or even two, staff members to attempt. This is where machine learning comes in….",
    "crumbs": [
      "AI and Machine Learning in Libraries"
    ]
  },
  {
    "objectID": "ml-ai.html#hands-on-activities-self-guided-tutorials",
    "href": "ml-ai.html#hands-on-activities-self-guided-tutorials",
    "title": "AI and Machine Learning in Libraries",
    "section": "Hands-On Activities & Self-Guided Tutorials",
    "text": "Hands-On Activities & Self-Guided Tutorials",
    "crumbs": [
      "AI and Machine Learning in Libraries"
    ]
  },
  {
    "objectID": "ml-ai.html#recommended-reading-viewing",
    "href": "ml-ai.html#recommended-reading-viewing",
    "title": "AI and Machine Learning in Libraries",
    "section": "Recommended Reading & Viewing",
    "text": "Recommended Reading & Viewing",
    "crumbs": [
      "AI and Machine Learning in Libraries"
    ]
  },
  {
    "objectID": "ml-ai.html#taking-things-further",
    "href": "ml-ai.html#taking-things-further",
    "title": "AI and Machine Learning in Libraries",
    "section": "Taking things further",
    "text": "Taking things further",
    "crumbs": [
      "AI and Machine Learning in Libraries"
    ]
  },
  {
    "objectID": "llms.html",
    "href": "llms.html",
    "title": "Understanding Large Language Models",
    "section": "",
    "text": "Introduction\nThis Topic Guide, based on a Hack & Yack delivered as part of the British Library’s Digital Scholarship Training Programme, offers a brief introduction to Large Language models (LLMS) by way of ChatGPT, as a means of demystifying both quickly. Through hands-on activities and case studies, we’ll explore potential challenges and opportunities for the use of LLMs and ChatGPT in current and future library services.",
    "crumbs": [
      "AI and Machine Learning in Libraries",
      "Understanding Large Language Models"
    ]
  },
  {
    "objectID": "llms.html#introduction",
    "href": "llms.html#introduction",
    "title": "Understanding Large Language Models",
    "section": "",
    "text": "What are Large Language Models (LLMs)?\nA large language model (LLM) is a type of machine learning model that can perform natural language processing tasks such as generating and classifying text, answering questions, and translating text.\nIf your eyes just crossed reading that sentence, no wonder, there’s a lot of terminology and jargon to unpack there in that one little sentence. Let’s go back a few steps and take it a little slower!\nIt helps to first understand a little bit about what machine learning is. Machine learning (ML) is a core technology that underpins a lot of work in artificial intelligence work today. Artificial intelligence is actually a broad field that encompasses the development of systems and machines capable of performing tasks that typically require human intelligence, such as reasoning, problem-solving, learning, and perception, and…chatting!\nNatural Language Processing (NLP) is a specialised area within artificial intelligence (AI) that looks specifically at the challenges of processing and understanding human language (another is Computer Vision (CV) which is, on the other hand, concerned with helping computers process and understand imagery in the vein of human vision). NLP plays a vital role in enhancing the capabilities of AI systems by working to make them more capable of natural and effective interaction with humans.\nNLP involves the development of algorithms, models, and systems for analysing, understanding and extracting meaningful information from textual data representing human language. The field relies heavily on the use of machine learning to make sense of our complex textual data, which might come from literature, historical documents, articles, twitter, wikipedia, you name it!\nMachine learning involves the development of algorithms and models that allow computers to learn patterns and relationships from data and make predictions on new data. Instead of being explicitly programmed for specific tasks, ML algorithms use data to learn and improve their performance over time.\nA machine learning algorithm is designed to recognize patterns, relationships, and trends in data and will adjust their internal parameters based on examples to improve their performance over time.\nA machine learning model represents what was learned by a machine learning algorithm. The model that’s created in the process and saved after running a machine learning algorithm on training data and represents the rules, numbers, and any other algorithm-specific data structures required to make predictions on new data.\nSo back to our definition:\nA large language model (LLM) is a type of machine learning model that can perform natural language processing tasks such as generating and classifying text, answering questions, and translating text.\nLanguage models are a type of machine learning model designed to predict the likelihood of a sequence of text, which means that they can be set up to predict the most likely way to continue a conversation. The models behind ChatGPT are large, complex neural networks that have been exposed to an enormous amount of text from books, articles, websites, and more. These models have learned something about patterns in grammar and word meaning, including the way that meaning arises contextually across multiple sentences and multiple turns in a conversation. When you ask ChatGPT a question, you are presenting the model with new information it tries to make a prediction on, in this case, it tries to generate a response that matches the pattern of conversation. Large language models are trained on massive amounts of text data and are essentially the backbone of NLP today. There are and have been for many years, large language models out there actually but ChatGPT has currently caught the popular imagination because of its publicly available interface and remarkable performance.\n\n\nWhat is ChatGPT?\nChatGPT is a platform providing an interface specifically to the large language models developed by OpenAI. The GPT stands for Generative Pre-Trained Transformers which is just a fancy way of saying that the models you are chatting with have already been trained on a lot of data.\nIt's a chatbot essentially designed to generate human-like text responses based on the input it receives. Or some say to think of it as a fancy predictive text generator. You ask questions or give prompts, and it provides responses in natural language, or rather, estimates what should come next in a conversation.\n\nWhat ChatGPT is NOT:\n\nGoogle Search Box: Unlike Google, ChatGPT doesn't search the internet for information. Instead, it generates responses based on a massive dataset it was trained on. This training dataset includes large segments of text sampled from the internet at a specific point in time, and so can reflect language describing content on the internet, but it doesn't have real-time access to the internet. When ChatGPT answers a question, it isn’t actually looking up information and then composing that information into a response; it's just making an estimation of a response based on patterns it has seen. So, when you ask it factual questions, especially ones with common answers or phrases, it might give you an answer that sounds right but remember this is because it’s mimicking what it has seen in its training data. Think of it perhaps as a very smart parrot, sometimes 'repeating' things it has seen before.\nHuman Mind: ChatGPT is not a human; it's a machine learning model. It doesn't understand or reason like a human. It generates evidently linguistic responses based on patterns it learned from text data.\n\n\n\nHow ChatGPT Generates Responses:\n\nLanguage Modelling: So ChatGPT models are members of this class of models we’re talking about: “large language models” (LLMs). A machine learning model represents what was learned by a machine learning algorithm. The model is created and saved after running a machine learning algorithm on training data and represents the rules, numbers, and any other algorithm-specific data structures required to make predictions on new data. Language models are designed to predict the likelihood of a sequence of text, which means that they can be set up to predict the most likely way to continue a conversation. The models behind ChatGPT are large, complex neural networks that have been exposed to an enormous amount of text from books, articles, websites, and more. These models have learned something about patterns in grammar and word meaning, including the way that meaning arises contextually across multiple sentences and multiple turns in a conversation. When you ask ChatGPT a question, it tries to generate a response that matches these patterns.\nContextual Understanding: ChatGPT also looks at the context of the question you ask, including what’s happened so far in your conversation and any instructions or details you offer about how it should respond. It tries to understand the context and generate a response that is contextually relevant, which can make its answers seem quite accurate.\nExisting Knowledge: It can recall and blend information it has observed in its training data. So, when you ask a factual question, it can sometimes generate a response that seems factual because it has encountered similar information during training. But, it can also make mistakes or provide information that is outdated or biassed because it doesn't have the ability to verify the accuracy of what it says, and it is influenced by any views inherent in its training data, whether they are right or wrong. It's like the parrot repeating something it heard: it can't check if what it's saying is true or up-to-date. That's why it's important to double-check information output by ChatGPT with reliable sources, especially when using ChatGPT for research or critical tasks.\nUser Feedback Loop: ChatGPT models like the latest GPT-4 (openai.com) have been tuned and improved over time with user feedback, as part of a model training process known as “reinforcement learning”. So for example, when users request things like python code, and try it out, users provide feedback on whether or not it worked. This feedback helps the model get better at generating code that is more likely to work.\n\n\n\nWhen best to use ChatGPT:\n\nIdea Generation: ChatGPT can help brainstorm ideas for projects, essays, or creative endeavours. For example, you can ask it for ideas on new business ventures, book plots, or marketing campaigns.\nThesaurus and Rephrasing: It's excellent for finding synonyms, rephrasing sentences, or improving the clarity of your writing. You can ask it to provide alternative words or rewrite a paragraph for better readability.\nCreative Writing: ChatGPT can assist with creative writing tasks, including writing short stories, poems, or generating dialogues for characters.\nSome Learning and Explanation: It can provide explanations and answers to questions on a wide range of very general topics, making it useful for learning new concepts or understanding complex ideas. But again, always best to double check against other trusted resources.\nLanguage Translation: ChatGPT can offer some basic translation assistance, such as translating phrases or short sentences between languages.\nGenerating code snippets: It may not produce highly complex or critical code reliably but you can use it as a starting point for some common coding tasks.\n\n\n\nQuerying structured data: ChatGPT can provide outputs in the form of data structures including for instance SQL queries and JSON. So for instance if we have an SQL database with information about the content of a corpus, we can prompt ChatGPT to output queries that would apply to that database. We can then begin to imagine an interface where a non-expert user could make such a query using their own natural language, and ChatGPT could provide a connection with the structured data. This is sometimes referred to as “function calling” in the ChatGPT literature.",
    "crumbs": [
      "AI and Machine Learning in Libraries",
      "Understanding Large Language Models"
    ]
  },
  {
    "objectID": "llms.html#relevance-to-the-library-sector-large-language-models-llm-and-chatgpt-uses-in-libraries-today",
    "href": "llms.html#relevance-to-the-library-sector-large-language-models-llm-and-chatgpt-uses-in-libraries-today",
    "title": "Understanding Large Language Models",
    "section": "Relevance to the Library Sector: Large Language Models (LLM) and ChatGPT Uses in Libraries Today",
    "text": "Relevance to the Library Sector: Large Language Models (LLM) and ChatGPT Uses in Libraries Today\n[Need to work on this section with written examples/more narrative around opportunities and challenges]\n\nA Tech Librarian Explains How to Build AI Literacy - Choice 360\nChatGPT: Implications for academic libraries | Cox | College & Research Libraries News (acrl.org)\nUsing GPT on Library Collections (Matt Miller)\nhttps://programminghistorian.org/en/lessons/interrogating-national-narrative-gpt",
    "crumbs": [
      "AI and Machine Learning in Libraries",
      "Understanding Large Language Models"
    ]
  },
  {
    "objectID": "llms.html#hands-on-activity-and-other-self-guided-tutorials",
    "href": "llms.html#hands-on-activity-and-other-self-guided-tutorials",
    "title": "Understanding Large Language Models",
    "section": "Hands-on activity and other self-guided tutorial(s)",
    "text": "Hands-on activity and other self-guided tutorial(s)\nThe following activity was delivered to British Library staff as part of a monthly Hack & Yack.\n\nGetting started\nFor this activity we’ll primarily use the freely available ChatGPT (openai.com) interface. For this you’ll need to have a free google account.\n\n\nFirst, a word on writing prompts\nTo get a useful response from ChatGPT, “prompting” is key. If you only ask a simple question, you may not be happy with the results and decide to dismiss the technology too quickly, but today’s purpose is to have a deeper play in order to develop our critical thinking and information evaluation skills, allowing us to make informed decisions about utilising tools like ChatGPT in our endeavours.\nSome best practices for writing a good prompt (helpful hints/tips gleaned from the suggested readings in this guide):\n\nGive the context. The more you explain the ins and outs of what you want ChatGPT to do, the more relevant your answer will be. For example, “You are an expert in [fill in the blank for your topic].”\nBe very specific and concrete about what you want it to do (and equally, what you don’t want it to do). For instance you may want to specify word count, how many items you’d like in a list, tone of voice, etc.\nGive clear instructions on what the output should look like, and be simple and concise in your language.\nProvide examples. Much like a human, ChatGPT often understands best when you provide an example for it to work with, especially if you want it to produce something that closely resembles something you’ve seen online.\nAsk ChatGPT to “act like” someone: Sometimes, it can help to start your prompt by asking ChatGPT to “act like” a certain type of person that would be particularly well-placed to respond to the query you're posing.\n\nIf you’re not satisfied with any part of the answer, you can keep building on it, asking ChatGPT to revise it in any way you like as it will continue on from previous enquiries in a session. (If you’d rather it not do that you can add “Please ignore all previous instructions” to start a prompt fresh). To learn more about prompting, there is a free online course: Learn Prompting.\n\n\nExploratory activities:\n\nHave a play generating responses to some of the below questions (or come up with your own)!\nCritically evaluate the responses you receive from ChatGPT.\n\nIs the information/response credible?\nAre there any biases in the responses?\nDoes the information align with what you know from other sources?\n\nConsider your findings, the strengths and weaknesses, ethical considerations and challenges of using AI tools such as this.\n\n\n\n\nTry this….\n**Example Prompts\nFurther considerations/Notes\n\n\n\n\nAsk ChatGPT to create a title for a new exhibition\n\n\n\n\nAsk ChatGPT to create an exhibition label for items in an exhibition\n“Write an exhibition label for this archived website http://moorfootru nners.blogspot.co.uk/”\n\n\n\nAsk ChatGPT to create a blog post on a topic for which you are very familiar\n\n\n\n\nAsk ChatGPT to help you come up with ideas for teaching\nTry something like this:\n“You are an academic librarian focusing on instruction. Please make an outline of important topics to cover for a classroom lecture on ChatGPT. This will be part of a series of instruction sessions about information literacy. You have already worked with this class on the basic concepts of information literacy. Create the outline as a bulleted list and follow it with a classroom activity based on one of the topics you’ve discussed about ChatGPT.”\nFrom: A Tech Librarian Explains How to Build AI Literacy - Choice 36 0\nWhen you get the results, you can then ask it to give you an additional activity or set of activities on the same topic.\nHave a play around with different training subject areas.\n\n\nAsk ChatGPT to write a bio for yourself, providing it with details for instance as a list of facts about you\n\n\n\n\nAsk ChatGPT to Act as a Translator\nTry something like this:\n“I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is”istanbulu cok seviyom burada olmak cok guzel”\nFrom: Awesome ChatGPT Prompts | This repo includes ChatGPT prompt curation to use ChatGPT better. \n\n\n\nAsk ChatGPT to create an outline for a PowerPoint presentation\n\n\n\n\nAsk ChatGPT to extract metadata from a provided text\n\n\n\n\nAsk ChatGPT to write a query for a suppositional SQL database that you describe\n“We have an SQL database with the following tables: 'books' and 'authors'. The 'books' table has columns 'title', 'date', and 'topic'. The 'authors' table has columns 'name', 'birth_date', 'death_date', and 'gender'. I'm going to write some questions about things in this database, and I would like you to respond with SQL queries that would find the information I'm asking about.”\nRESPONSE: “Of course! Feel free to ask any questions you have about the database, and I'll provide you with SQL queries to retrieve the information you need. Please go ahead and ask your questions.”\nINPUT: “I'd like to find books about the second world war written by women born after the war ended.”\nRESPONSE: “To find books about the Second World War written by women born after the war ended, you can use the following SQL query:”\nSELECT b.title, b.date, a.name\nFROM books b\nJOIN authors a ON b.author_id = a.author_id\nWHERE b.topic = 'Second World War'\nAND YEAR(a.birth_date) &gt; 1945\nAND a.gender = 'female';\n\n\n\nHave a look at this project Matt Miller did experimenting with [Using GPT on Library Collections (thisismattmill er.com)]{.underlin e}\n“You are a helpful assistant that is summarizing and extracting data from a journal written by Susan B. Anthony in {RECORD_DATE_HERE}. You only answer using the text\ngiven to you. You do not make-up additional information, the answer has to be contained in the text provided to you. Each page is a diary entry or financial bookkeeping. You will structure your answer in valid JSON, if there are any quote marks in the content escape them as \".”\n“If the following text contains multiple journal entries, extract each one into an array of valid JSON dictionaries. Each dictionary represents one of the entries, extract the date and\nthe date again in the format yyyy-mm-dd and the city or state it was written in and other geographical locations mentioned that entry and people mentioned that entry and the complete\nfull text of the entry and a one sentence summary of the text, using the JSON keys dateText, dateFormated, cityOrState, geographicalLocations, people, fullText, summaryText: {FULL_TEXT_HERE}“\nThinking about this project, could you think of a similar collection that you might be able to experiment with to parse data similarly? How might you like to re-write the prompt for your own project?\n\n\nTry to use it to create social media posts\nThere is a new network called CHOSN for those working in Galleries-Libr aries-Archives-Museums (GLAM) and cultural heritage organisations as research support and research-active staff. This network is a community of practice for research support and research-active staff who work in GLAM organisations interested in developing and sharing open scholarship knowledge and skills, organising events, and supporting each other in this area. Can you write social media post for 140 character to announce this network and call people to join in?\n\n\n\nPROMPT: Act as a librarian advising a history student in the UK doing research into the third plague pandemic in India during the early 20th century. What archival resources could they use?\nRESPONSE: Certainly! If you're a history student in the UK researching the Third Plague Pandemic in India during the early 20th century, there are several archival resources you can explore to enhance your research. These archives will provide you with primary sources, documents, and historical records that can help you gain a deeper understanding of this important historical event. Here are some key archival resources to consider:\n1. **The National Archives (TNA) of the United Kingdom**:\n- TNA holds records related to British colonial administration in India during the early 20th century. Look for documents related to public health, sanitation, and official correspondence about the plague.\n2. **The India Office Records**:\n- These records are part of the British Library's holdings and contain a wealth of information on India during the colonial period. You can find reports, letters, and administrative documents related to the Third Plague Pandemic.\n3. **The British Library**:\n- The British Library has a substantial collection of materials related to India, including newspapers, periodicals, and publications from that era. You can find newspaper articles, books, and reports that discuss the plague's impact in India.\n4. **The Wellcome Collection**:\n- The Wellcome Collection in London has an extensive library and archive of materials related to the history of medicine. You may find documents, photographs, and medical reports pertaining to the plague in India.\n5. **Local Archives in India**:\n- Depending on your specific focus within India, you should also explore local archives and libraries. For example, the National Archives of India in Delhi and state archives may have valuable records.\n6. **Digital Collections**:\n- Many institutions, including the British Library and the Wellcome Collection, have digitized collections that you can access online. These digital resources can be very helpful for remote research.\n7. **University Libraries**:\n- Don't forget to check with your university's library. They may have subscriptions to digital archives and databases that can provide access to primary source materials and scholarly articles related to the Third Plague Pandemic in India.\n8. **Academic Journals**:\n- Look for scholarly articles in history and medical history journals. JSTOR and other academic databases can be valuable for finding secondary sources and research papers.\n9. **Interlibrary Loan Services**:\n- If you find a source or book that's not available in your university's library, you can request it through interlibrary loan services. This expands your access to materials from other institutions.\n10. **Archival Finding Aids**:\n- Be sure to use finding aids and catalog search tools provided by these institutions to locate specific documents and records related to the Third Plague Pandemic.\nRemember to take thorough notes, document your sources meticulously, and consult with your professors or advisors for guidance throughout your research process. Good luck with your research into this important historical topic!\n\n\n\nPROMPT: Act as an archivist producing a catalogue record for an archival document. What subject, place and name authorities or terms would you choose for the following text? [gave it c50% of the full text transcription of IO R/F/4/1754/71645]\nRESPONSE: Here's a suggested catalog record for the provided archival document, along with subject, place, and name authorities/terms:\nTitle: Development of Hemp Cultivation for Cordage Manufacturing\nAuthor: [Author's Name if available]\nDate: [Date of the Document, if available]\nDescription:\nThis archival document explores the historical development of hemp cultivation for cordage (rope) production, emphasizing its critical importance for mechanical purposes and ship rigging during the 19th century. It discusses the transition from skin and leather ropes to vegetable fiber, particularly hemp, and the widespread cultivation and commerce of hemp in various nations. The document highlights the vital role of hemp during wartime and its impact on British shipping during supply disruptions. Additionally, it underscores the attention given to hemp cultivation in India and its various applications, focusing on the Cannabis Sativa plant.\nSubjects:\nCordage Industry\nHemp Cultivation\nRope Manufacturing\nShip Rigging\nHemp Fiber\nAgriculture in India\nColonial Agriculture\nInternational Commerce\nWar Supply Chains\nMechanical Engineering\nFiber Plants\nPlaces:\nUnited Kingdom\nIndia\nNorth America\nRussia\nArabia\nPersia\nChina\nEgypt\nTurkey\nEurope\nAsia\nNames:\nAlexandre Yersin (if mentioned as the author or contributor)\nDr. Roxburgh (for his contributions to hemp cultivation in India)\nNotes:\nThis document provides historical insights into the cultivation of hemp for cordage and its significance in various regions during the 19th century, with a focus on its mechanical properties and wartime importance.\nPlease note that the specific author and date of the document were not provided in the text you provided. If this information is available, it should be included in the catalog record. Additionally, you may need to consult relevant authority files or controlled vocabularies to ensure accuracy in subject, place, and name authorities.\nCOMMENT: The inclusion of Yersin as a suggested authority is interesting / worrying, as he had cropped up in an answer to a previous question, and I had told it to disregard all of the previous conversation data before posting the cataloguing prompt…\nIn terms of indexing, it included a lot of incidental references in the text which a cataloguer would not include as subject or place index terms [should flag at this point that I did not write the BL’s catalogue entry for this]]\nI should really give it the full text before judging the description…",
    "crumbs": [
      "AI and Machine Learning in Libraries",
      "Understanding Large Language Models"
    ]
  },
  {
    "objectID": "llms.html#recommended-reading-viewing",
    "href": "llms.html#recommended-reading-viewing",
    "title": "Understanding Large Language Models",
    "section": "Recommended Reading & Viewing",
    "text": "Recommended Reading & Viewing\n\n40 Best ChatGPT Prompts You Simply Have To Try in 2023 (tech.co)\nA Tech Librarian Explains How to Build AI Literacy - Choice 360\nChatGPT: Implications for academic libraries | Cox | College & Research Libraries News (acrl.org)\nUsing GPT on Library Collections (Matt Miller)\nhttps://programminghistorian.org/en/lessons/interrogating-national-narrative-gpt\nWelcome | Learn Prompting: Your Guide to Communicating with AI",
    "crumbs": [
      "AI and Machine Learning in Libraries",
      "Understanding Large Language Models"
    ]
  },
  {
    "objectID": "llms.html#taking-the-next-steps",
    "href": "llms.html#taking-the-next-steps",
    "title": "Understanding Large Language Models",
    "section": "Taking the next steps",
    "text": "Taking the next steps",
    "crumbs": [
      "AI and Machine Learning in Libraries",
      "Understanding Large Language Models"
    ]
  },
  {
    "objectID": "collectionsasdata.html",
    "href": "collectionsasdata.html",
    "title": "1  Collections as Data: Getting Started",
    "section": "",
    "text": "1.1 Introduction: What is the concept of Collections as Data and how can my institution get started?\nGLAM (Galleries, Libraries, Archives and Museums) institutions have been making their content available to the public and researchers in a variety of formats for different purposes for decades. From maps, images, text, historical newspapers or postcards, digitising collections and displaying our items online are at the core of making this information accessible for research and enjoyment. But recent advances in the use of Artificial Intelligence and Machine Learning (link to topic guide) have transformed the way in which our users expect to access, view, use and search our collections. As the demand for computationally accessible cultural heritage collections continues to grow, and we’re being asked to provide our collections in the form of datasets for instance, how do we go about this practically?\nIn this new context, where GLAM institutions now find themselves playing a leading role as data providers and data curators, the Collections as Data concept emerged as a new approach, guidance and framework to support responsible development and computational use of digital cultural heritage collections. By computational use we mean the application of computational techniques such as natural language process, computer vision, and more to the analysis, exploration and reuse at scale of digitised cultural heritage content. For more use cases on AI and Machine Learning in Libraries see our related topic guide. [Link to the topic guide on AI/ML]\nThree particularly useful outputs from the Collections as Data community of practice are:\n“Want to support collections as data at your institution, but not sure how to begin? Drawing on what we learned from engaging with practitioners and researchers throughout the Always Already Computational project, the project team compiled a list of 50 Things you can do to get started. 50 Things is intended to open eyes, stimulate conversation, encourage stepping back, generate ideas, and surface new possibilities. If any of that gets traction, then perhaps you can make the case for investing in collections as data at your institution in a meaningful, if not systematic, way”\n“The Vancouver Statement suggests a set of principles for thinking through questions that collections-as-data work produces, as part of an expanding global, interprofessional, and interdisciplinary effort to empower memory, knowledge, and data stewards (e.g., practitioners and scholars) who aim to support responsible development and computational use of collections as data. This stewardship role only grows in importance as artificial intelligence applications, trained on vast amounts of data, including collections as data, impact our lives ever more pervasively.”\nDeveloped as a result of a community-led effort, the checklist covers different aspects such as providing a suggested citation, including documentation about the datasets (e.g., README files or tutorials) or sharing examples of use (e.g., prototypes or Jupyter Notebooks).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Collections as Data: Getting Started</span>"
    ]
  },
  {
    "objectID": "collectionsasdata.html#introduction-what-is-the-concept-of-collections-as-data-and-how-can-my-institution-get-started",
    "href": "collectionsasdata.html#introduction-what-is-the-concept-of-collections-as-data-and-how-can-my-institution-get-started",
    "title": "1  Collections as Data: Getting Started",
    "section": "",
    "text": "Fifty things (2018)\n\n\n\nVancouver Statement on Collections as data (2023)\n\n\n\nA Checklist to Publish Collections as Data in GLAM Institutions (2023)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Collections as Data: Getting Started</span>"
    ]
  },
  {
    "objectID": "collectionsasdata.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "href": "collectionsasdata.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "title": "1  Collections as Data: Getting Started",
    "section": "1.2 Relevance to the Library Sector (Case Studies/Use Cases)",
    "text": "1.2 Relevance to the Library Sector (Case Studies/Use Cases)\nMany institutions have started to adopt the collections as data principles to varying degrees, often combining publication of digital collections suitable for computational use, with a lab offering technical support to use them. You might notice that the examples below are all slightly different implementations of the principles though as each institution will necessarily need to decide for themselves, based on their individual goals and constraints (such as lack of resources, staff or IT skills) how to practically adopt the Collections as Data principles.\n\nData Foundry at the National Library of Scotland provides datasets in the form of downloadable files. Each of them includes a website with transparent information about the creation and curation of the content. It also provides examples of use and prototypes in the form of Jupyter Notebooks.\nNational Library of Luxembourg provides a digital collection based on Historical newspapers. It follows an innovative approach by providing different datasets in terms of the size and the content according to the purpose of the reuse (e.g., getting started or Big Data).\nBritish Library Labs provides a selection of datasets made available under open licences to experiment.\nDATA-KBR-BE is a project that aims at facilitating data-level access to KBR’s digitised and born-digital collections for digital humanities research.\nBiblioteca Virtual Miguel de Cervantes (BVMC Labs) is a digital library that published its bibliographic catalogue in the form of Linked Open Data. It also provides examples of use by means of of Jupyter Notebooks.\n\nMore advanced approaches are focused on the concept of data spaces, which are new cloud environments in which data can be shared for research use, while also allowing data suppliers to retain rights and control over the data. This can be useful for contexts in which the access of the data is restricted (e.g., geographic region, licensed content). A workflow to publish Collections as Data: the case of Cultural Heritage data spaces ) gives more information on this topic in the context of the European common data space for cultural heritage.\nIt is important to note that institutions need to carefully consider how and for what purpose they want to publish their digital content. For instance, the National Library of the Netherlands has recently restricted access to collections for training commercial AI. See our topic guide on Copyright and Licensing for more on that.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Collections as Data: Getting Started</span>"
    ]
  },
  {
    "objectID": "collectionsasdata.html#hands-on-activity-and-other-self-guided-tutorials",
    "href": "collectionsasdata.html#hands-on-activity-and-other-self-guided-tutorials",
    "title": "1  Collections as Data: Getting Started",
    "section": "1.3 Hands-on activity and other self-guided tutorial(s)",
    "text": "1.3 Hands-on activity and other self-guided tutorial(s)\nOne simple activity you could do at your institution is to gather a group of like-minded colleagues together and have a read through Fifty things, Vancouver Statement on Collections as data and/or A Checklist to Publish Collections as Data in GLAM Institutions and have a look at some of the case studies above, and as a group consider the questions:\n\nAre there some activities suggested that are already underway?\nCan you identify one or two simple things that your institution could do now in order to start using these principles?\nWhat might you like “collections as data” to look like at your institution?\n\nIf you’d like to get a sense of how people are reusing collections published as data, the GLAM Workbench and the new computational access section of the International GLAM Labs Community website both have tutorials that can walk you through using cultural heritage datasets in a variety of ways.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Collections as Data: Getting Started</span>"
    ]
  },
  {
    "objectID": "collectionsasdata.html#recommended-readingviewing",
    "href": "collectionsasdata.html#recommended-readingviewing",
    "title": "1  Collections as Data: Getting Started",
    "section": "1.4 Recommended Reading/Viewing",
    "text": "1.4 Recommended Reading/Viewing\nIf you are interested in reading more about the collections as data concept we highly recommend the Zotero | Groups &gt; collections as data - projects, initiatives, readings, tools, datasets which is an open bibliography collaboratively maintained by the community of practice of projects, readings, initiatives, tools, and datasets that are in some way or another related to collections as data.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Collections as Data: Getting Started</span>"
    ]
  },
  {
    "objectID": "collectionsasdata.html#taking-the-next-step",
    "href": "collectionsasdata.html#taking-the-next-step",
    "title": "1  Collections as Data: Getting Started",
    "section": "1.5 Taking the next step",
    "text": "1.5 Taking the next step\nJoining the International GLAM Labs Community is a great way to get started on the path of opening your collections up as data as well as the Collections as Data - Google Group as both communities are very active and have a wide range of experience and expertise to share on this topic.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Collections as Data: Getting Started</span>"
    ]
  },
  {
    "objectID": "iiif.html",
    "href": "iiif.html",
    "title": "IIIF",
    "section": "",
    "text": "Introduction: What is IIIF?\nIIIF (pronounced “triple-eye-eff”) stands for the International Image Interoperability Framework. Quite a tongue twister that one, but it broadly represents two things:",
    "crumbs": [
      "IIIF"
    ]
  },
  {
    "objectID": "iiif.html#introduction-what-is-iiif",
    "href": "iiif.html#introduction-what-is-iiif",
    "title": "IIIF",
    "section": "",
    "text": "a set of open standards for delivering high-quality, attributed digital objects online at scale.\nthe open, international community of software developers, libraries, researchers, educators, museums, universities, creative agencies, and more working together to develop and implement the IIIF APIs to make the above open standards happen.\n\n\nOpen Standard\nEver try to look at a large high-resolution digitised manuscript online only for it to take ages to load, and when it finally does you have no way to actually move around the image easily nor see any of the metadata or annotations related to it?\nOr maybe spent months on end negotiating the terms and methods around sending copies of a variety of differently sized individual images to another institution for them to host as part of collaborative project?\nIIIF brings a whole new efficiency to the way in which we in the cultural heritage sector go about sharing and making our digitised collections available online, while greatly expanding the functionality around the way users interact with them. It’s an open standard, collaboratively developed and maintained by a host of cultural heritage institutions around the world that defines a consistent method for the delivery of images and audio/visual files from servers to different environments on the Web where they can then be viewed and interacted with in many ways.\nIIIF basically specifies a way for browsers to display an image or audio/visual files in a way that enables much richer functionality on the Web:\n\nMakes it easier to display large images on the web in a way that is scalable (enabling deep zoom)\nAllows easy comparison between two objects, connecting and uniting materials across institutional boundaries\nDisplays structure and metadata and annotations with the digital collection item. (For a digitised manuscript for instance this might be page order and searchable text, for audio/visual materials, that means being able to deliver complex structures (such as several reels of film that make up a single movie) along with things like captions, transcriptions/translations, annotations, and more.)\n\n\n“At its simplest, IIIF uses APIs to load images quickly and zoom smoothly without additional loading time. But IIIF also allows you to do much more, including pulling IIIF-enabled images from different sites into viewers for comparison without downloading them (at full resolution), and enabling saving links to details of images or portions of A/V files for future reference. IIIF also allows you to use many open-source tools that help you to compare, annotate, transcribe, collaborate, and more. You can even gather multiple IIIF images together from across multiple archival collections and/or institutions to create projects or exhibits without advanced technical skills”. -From IIIF for Archives\n\nMaking your collections IIIF enabled makes it easier to share your content online in a consistent way, enabling portability across different IIIF enabled viewers. This means that rather than endlessly creating copies of your images all over the world for different projects, they can stay on your same IIIF Image server, but be accessed and displayed by viewers hosted at institutions elsewhere.\n\n\nOpen Community\nThe IIIF community is made up of over 100 major cultural heritage organisations worldwide who have formally adopted it, including many of our very own LIBER members. It was started in 2011 as a collaboration between The British Library, Stanford University, the Bodleian Libraries (Oxford University), the Bibliothèque nationale de France, Nasjonalbiblioteket (National Library of Norway), Los Alamos National Laboratory Research Library, and Cornell University. It’s a really nice example of an open, grassroots but global community effort, backed by a consortium of leading cultural institutions, who have been working together to develop and implement this new capability for decades and solve their shared problems with delivering, managing, sharing, and working with their resources.\n\n\nWhat would I need to do to make my collection IIIF enabled?!\nIf you want the deep nitty gritty technical stuff around all the APIs and how they fit together there is quite a bit of implementation documentation on their website that goes into all this. But essentially, the basic set up behind making your own digitised collections “IIIF enabled”, as they say, looks a little something like this:\n\nSet-up a IIIF image server (you can choose one developed by the community, or there are IIIF-compatible image servers available from vendors or other web hosts), move your content there and implement the IIIF Image API to make those images and audio/video materials available from there.\nImplement the IIIF Presentation API which creates the all important IIIF Manifest files (also many open source or vendor products can help handle this bit too) for each of your objects. This Manifest file is really the prime unit in IIIF, it essentially combines and packages in json code, information about your images and structural data from your metadata source. It lists all the information that makes up your new IIIF enabled object, from how to display it to what information IIIF viewers should (and should not) display (such as structure or the order of pages, or even as minute as where an illustration is located within an image if you like). If you want to see an example of what one looks like this is a IIIF Manifest from the Bodleian Libraries at University of Oxford relating to this collection item. Each manifest has its own URL and that’s the bit you’ll use to do cool things with the object in different IIIF viewers, such as allowing a manuscript to be easily dragged and dropped into Mirador for instance for comparison with other IIIF enabled manuscripts.\nChoose one of the many IIIF enabled viewers for displaying your images and add it to your own collection site. Again, looking at that same collection item record above, note in the upper left hand-corner (see image below) there is an option to view in Mirador or Universal Viewer which are two different styles of IIIF viewer that afford different functionalities.\nConsider making your IIIF Manifests available publicly for download so users can work with them in all the interesting ways you’ve now enabled!",
    "crumbs": [
      "IIIF"
    ]
  },
  {
    "objectID": "iiif.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "href": "iiif.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "title": "IIIF",
    "section": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "text": "Relevance to the Library Sector (Case Studies/Use Cases)\nIIIF was initiated by a bunch of libraries and cultural heritage collections holders and it shows! It was proposed in late 2011 as a collaboration between The British Library, Stanford University, the Bodleian Libraries (Oxford University), the Bibliothèque nationale de France, Nasjonalbiblioteket (National Library of Norway), Los Alamos National Laboratory Research Library, and Cornell University. The intention of the consortium has always been to combine resource and effort in building viewers that reflected the way we wanted our digital collections to be displayed online, rather than everyone still spending time and resource making our own custom viewers and building our own content silos. It’s brought a huge amount of efficiency too in the way that we share images with each other and researchers. It’s changed the way collaborative projects are undertaken where endless metadata mapping exercises, contract negotiations around re-use and hosting, and the copying and shipping of digitised materials on external hard drives were the norm.\nThere are quite a number of use cases and case studies available on the IIIF Demos page but let’s have a quick look at three real life (and canonical) examples of IIIF in action.\n\nDeep Zoom and Annotations\nThe example here is of the Ōmi Kuni-ezu 近江國絵圖 Japanese Tax map created in 1837. It’s meant to be read in the round by someone standing in the middle–you can see the scale when this zooms out– the map is eleven by seventeen FEET, and the person standing next to it, Wayne who works in the library at Stanford, is six feet four inches tall. This image is a composite of 158 individual images with a file size of 1.27Gb. IIIF allows just enough of an image to be delivered to a viewer–going from a whole image to just the part that they are zooming in on. Without IIIF, an end user might have to download an extremely large file, but using IIIF provides a smooth and easy viewing experience.\n\nHave a play and view this image in their Universal viewer here\n\n\nVirtual Reconstruction\nThe virtual reconstruction of this damaged manuscript from Châteauroux in France (Grandes Chroniques de France, ca. 1460) is probably one of the most well-known and best examples of the power of IIIF to support this use case (and my own personal favourite!). At some point in the manuscripts history, fourteen of its illuminations were cut out. These illuminations eventually ended up at the Bibliothèque nationale de France in the 19th century and were digitised individually. In the demo you see the reuniting of the miniatures with the full manuscript as IIIF allows a virtual repositioning of the cut out decorations with the text, virtually reconstructing the manuscript online using the Mirador Viewer so it reflects its original state.\n\nI highly recommend having a play around with the Mirador Viewer: Châteauroux demo.",
    "crumbs": [
      "IIIF"
    ]
  },
  {
    "objectID": "iiif.html#hands-on-activity-and-other-self-guided-tutorials",
    "href": "iiif.html#hands-on-activity-and-other-self-guided-tutorials",
    "title": "IIIF",
    "section": "Hands-on activity and other self-guided tutorial(s)",
    "text": "Hands-on activity and other self-guided tutorial(s)\nThe following tutorials are two of my favourite recommendations for colleagues interested in having a play with IIIF manifests yourself and in the process gaining a practical understanding of how they work, and the benefits!\n\nIIIF Online Workshops The community itself has created a number of excellent and free self-paced tutorials and though they host live online workshops for a fee, these are recorded and available and useful for newcomers for free afterwards. In fact staff at British Library have walked through these self-guided resources online quite often with great success. There is also the opportunity to hire a IIIF Trainer to come to deliver live bespoke training directly to your institution (for a fee), which we have also partaken in!\nWorking with IIIF images in education, communication and research This is a self-guided workshop available online in Dutch and English and has some excellent exercises to get you familiar with finding IIIF manifests in catalogues and importing them into different viewers. I highly recommend making some time (they recommend 120 minutes) to read through this and try out some of the exercises.",
    "crumbs": [
      "IIIF"
    ]
  },
  {
    "objectID": "iiif.html#recommended-readingviewing",
    "href": "iiif.html#recommended-readingviewing",
    "title": "IIIF",
    "section": "Recommended Reading/Viewing",
    "text": "Recommended Reading/Viewing\nThere is a useful collection of articles and data related to IIIF being compiled by the community at https://zenodo.org/communities/iiif/records?q=&l=list&p=1&s=10&sort=newest\nThe IIIF organisation has also created a number of useful resources alongside their training materials such as How It Works, a plain-language guide to how the IIIF API’s work and a glossary of “Key concepts you’ll encounter when working with IIIF”",
    "crumbs": [
      "IIIF"
    ]
  },
  {
    "objectID": "iiif.html#taking-the-next-step",
    "href": "iiif.html#taking-the-next-step",
    "title": "IIIF",
    "section": "Taking the next step",
    "text": "Taking the next step\nLearning about IIIF can be overwhelming at first, especially if you’re not a programmer, but the IIIF Community is a very supportive and engaged one and has created a number of ways to get involved and find support and help.\nI recommend checking out their community page IIIF Community to find details of their next open community calls, or to join their Slack Channel where you can post questions and join the discussion with other users.\nThere is also a massive list of resources, Awesome IIIF, compiled and maintained by the IIIF Community if you are looking to take your knowledge a bit further and dig deeper into some of the exciting implementations of IIIF.",
    "crumbs": [
      "IIIF"
    ]
  },
  {
    "objectID": "api.html",
    "href": "api.html",
    "title": "What is an API?",
    "section": "",
    "text": "Introduction",
    "crumbs": [
      "What is an API?"
    ]
  },
  {
    "objectID": "api.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "href": "api.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "title": "What is an API?",
    "section": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "text": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "crumbs": [
      "What is an API?"
    ]
  },
  {
    "objectID": "api.html#hands-on-activity-and-other-self-guided-tutorials",
    "href": "api.html#hands-on-activity-and-other-self-guided-tutorials",
    "title": "What is an API?",
    "section": "Hands-on activity and other self-guided tutorial(s)",
    "text": "Hands-on activity and other self-guided tutorial(s)",
    "crumbs": [
      "What is an API?"
    ]
  },
  {
    "objectID": "api.html#recommended-readingviewing",
    "href": "api.html#recommended-readingviewing",
    "title": "What is an API?",
    "section": "Recommended Reading/Viewing",
    "text": "Recommended Reading/Viewing",
    "crumbs": [
      "What is an API?"
    ]
  },
  {
    "objectID": "api.html#taking-the-next-step",
    "href": "api.html#taking-the-next-step",
    "title": "What is an API?",
    "section": "Taking the next step",
    "text": "Taking the next step",
    "crumbs": [
      "What is an API?"
    ]
  },
  {
    "objectID": "getting-started-with-programming.html",
    "href": "getting-started-with-programming.html",
    "title": "Getting Started With Programming",
    "section": "",
    "text": "Introduction\naergergdfvdf",
    "crumbs": [
      "Getting Started With Programming"
    ]
  },
  {
    "objectID": "getting-started-with-programming.html#relevance-to-the-library-sector",
    "href": "getting-started-with-programming.html#relevance-to-the-library-sector",
    "title": "Getting Started With Programming",
    "section": "Relevance to the Library Sector",
    "text": "Relevance to the Library Sector\naergaergaerg",
    "crumbs": [
      "Getting Started With Programming"
    ]
  },
  {
    "objectID": "getting-started-with-programming.html#hands-on-exercises-self-guided-tutorials",
    "href": "getting-started-with-programming.html#hands-on-exercises-self-guided-tutorials",
    "title": "Getting Started With Programming",
    "section": "Hands-On Exercises & Self-Guided Tutorials",
    "text": "Hands-On Exercises & Self-Guided Tutorials\naergeargaerg",
    "crumbs": [
      "Getting Started With Programming"
    ]
  },
  {
    "objectID": "getting-started-with-programming.html#recommended-reading-further-resources",
    "href": "getting-started-with-programming.html#recommended-reading-further-resources",
    "title": "Getting Started With Programming",
    "section": "Recommended Reading & Further Resources",
    "text": "Recommended Reading & Further Resources\nragergeargaergaer",
    "crumbs": [
      "Getting Started With Programming"
    ]
  },
  {
    "objectID": "r.html",
    "href": "r.html",
    "title": "R",
    "section": "",
    "text": "All things R :)",
    "crumbs": [
      "Getting Started With Programming",
      "R"
    ]
  },
  {
    "objectID": "python.html",
    "href": "python.html",
    "title": "Python",
    "section": "",
    "text": "All things Python :)",
    "crumbs": [
      "Getting Started With Programming",
      "Python"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Recommended Reading Lists",
    "section": "",
    "text": "There is no shortage of recommended reading lists out there, here we try and highlight a few of the most up to date and useful lists out there for the sector today!\nZotero Library for Digital Scholarship and Data Science Essentials for Library Professionals\nThis library contains links to all of the resources referenced within Topic Guides and across our site.\nZotero | Groups &gt; collections as data - projects, initiatives, readings, tools, datasets\nOngoing collection of projects, readings, initiatives, tools, and datasets that are in some way or another related to collections as data. This group is an open resource, welcoming contributions from anyone who has a resource to share.\n[TODO] Data Science in Libraries, is there a Zotero?",
    "crumbs": [
      "**GENERAL RESOURCES**",
      "Recommended Reading Lists"
    ]
  },
  {
    "objectID": "reports.html",
    "href": "reports.html",
    "title": "Skills Competency Frameworks & Key Reports",
    "section": "",
    "text": "The following are Skills Competency Frameworks & Key Reports relating to supporting Digital Scholarship and Data Science for library staff\n\nLIBER Publications\n\nLIBER Digital Skills for Library Staff & Researchers Working Group - LIBER Europe have lots of resources here, including a very useful diagram Identifying Open Science Skills for Library Staff & Researchers\nLIBER Job Description Repository Contains job description examples for Digital Curator and other digital roles which reference the types of skills required for such work.\nEurope’s Digital Humanities Landscape: A Study From LIBER’s Digital Humanities & Digital Cultural Heritage Working Group is a report based on a Europe-wide survey run by LIBER’s Digital Humanities & Digital Cultural Heritage Working Group. The survey focused on digital collections and the activities libraries undertake around them. It covered the following topics and themes including staffing/skills\n\n\n\nKey Publications specific to digital scholarship and data science skills for research library staff\n\nThe British Library and the Arts and Humanities Research Council published a report on skills: Scoping Skills and Developing Training Programme for Managing Repository Services in Cultural Heritage Organisations. There is a very useful section (Section 3.) that references several other digital skills frameworks for research library staff across Europe.\nLippincott, Joan K. Directions in Digital Scholarship: Support for Digital, Data-Intensive, and Computational Research in Academic Libraries. Coalition for Networked Information, June 2023. https://doi.org/10.56561/ULHJ1168\nPadilla, Thomas. ‘Responsible Operations: Data Science, Machine Learning, and AI in Libraries’. OCLC, 26 August 2020. https://www.oclc.org/research/publications/2019/oclcresearch-responsible-operations-data-science-machine-learning-ai.html.\nCordell, R. C. (2020). Machine Learning + Libraries: A Report on the State of the Field. LC Labs, Library of Congress. https://labs.loc.gov/static/labs/work/reports/Cordell-LOC-ML-report.pdf\nFederer L. Defining data librarianship: a survey of competencies, skills, and training. J Med Libr Assoc. 2018 Jul;106(3):294-303. doi: 10.5195/jmla.2018.306. Epub 2018 Jul 1. PMID: 29962907; PMCID: PMC6013124.\n\n\n\nGeneral Competencies for Librarians which include reference to digital\n\nAmerican Library Association (ALA) Library Competencies (Various roles): Library Competencies | Tools, Publications & Resources (ala.org) (USA)\nCanadian Association of Research Libraries Competencies for Librarians in Canadian Research Libraries Publications and Documents (including specifically Competencies-Final-EN-1-2.pdf (Canada)\nCILIP: the library and information association Professional Knowledge & Skills Base - (UK)",
    "crumbs": [
      "**GENERAL RESOURCES**",
      "Skills Competency Frameworks & Key Reports"
    ]
  },
  {
    "objectID": "training-platforms.html",
    "href": "training-platforms.html",
    "title": "Training Platforms",
    "section": "",
    "text": "When you’re ready to go further and have a better idea of the specific skills you need for a particular task, we can recommend having a good search through these excellent platforms which host a great many in-depth training materials:\n\nDARIAH-Campus\nDARIAH is a pan-European infrastructure for arts and humanities scholars working with computational methods. It supports digital research as well as the teaching of digital research methods. Though not specific to the library professional context, tutorials here are useful for applying techniques to digital collections. https://campus.dariah.eu/\n\n\nThe Glam Workbench\nThe GLAM Workbench is the brainchild of Tim Sherratt, a historian, and is a collection of Jupyter notebooks to help you explore and use data from GLAM institutions (galleries, libraries, archives, and museums). It includes tools, tutorials, examples, hacks, and even some pre-harvested datasets. It’s aimed at researchers in the humanities but has useful tutorials for anyone interested in working with GLAM data. https://glam-workbench.net/\n\n\nIneo\nIneo is a project developed and maintained by CLARIAH that lets you search, browse, find and select digital resources for research in humanities and social sciences. At the end of 2024 it will offer access to thousands of tools, datasets, workflows, standards and learning material. It is a work in progress so do keep that in mind when browsing. https://www.ineo.tools/\n\n\nLibrary Carpentry\nLibrary Carpentry is an international volunteer community, under the Carpentries, focussed building software and data skills within library and information-related communities. The lessons here are meant to be taught as workshops led by a Carpentries certified instructor (for a fee) but you may find it useful to have a read through the content which is open and available to all. https://librarycarpentry.org/\n\n\nThe Programming Historian\nThe Programming Historian has been publishing peer-reviewed tutorials on digital tools and techniques for humanists since 2008 and though they’re generally aimed at academic researchers, staff at British Library have found them highly useful over the years in their own work! https://programminghistorian.org/en/",
    "crumbs": [
      "**GENERAL RESOURCES**",
      "Training Platforms"
    ]
  },
  {
    "objectID": "networks.html",
    "href": "networks.html",
    "title": "Useful Networks",
    "section": "",
    "text": "LIBER Working Groups\nWorking groups are open to staff at participating LIBER Member institutions: - LIBER Data Science in Libraries - LIBER Digital Scholarship & Digital Cultural Heritage - Or have a look at the other LIBER Working Groups - LIBER Europe",
    "crumbs": [
      "**GENERAL RESOURCES**",
      "Useful Networks"
    ]
  },
  {
    "objectID": "networks.html#international-networks",
    "href": "networks.html#international-networks",
    "title": "Useful Networks",
    "section": "International Networks",
    "text": "International Networks\n\nAI4LAM\nCode4Lib\nElectronic Literature Organisation\nFlickr Commons\nGlam Labs International\nIIIF/UV Open Collective\nIMPACT Centre of Competence\nMuseums Computer Group\nTranskribus\nWikidata Community)",
    "crumbs": [
      "**GENERAL RESOURCES**",
      "Useful Networks"
    ]
  },
  {
    "objectID": "networks.html#national-networks-european",
    "href": "networks.html#national-networks-european",
    "title": "Useful Networks",
    "section": "National Networks (European)",
    "text": "National Networks (European)\n\nIreland/UK\n\nRLUK Digital Scholarship Network",
    "crumbs": [
      "**GENERAL RESOURCES**",
      "Useful Networks"
    ]
  },
  {
    "objectID": "project-overview.html",
    "href": "project-overview.html",
    "title": "Project Overview",
    "section": "",
    "text": "Core Project Team\nThe site and content are maintained by the Co-Chairs and select Members of the collaborating WGs listed here who act as the core project delivery team and editors of this resource.\nJodie Double, Editor DSDCH\nPéter Király, Editor DSLib\nNora McGregor, Editor DSDCH\nNeha Moopen, Site Maintainer DSLib\nPeter Verhaar, Editor DSLib",
    "crumbs": [
      "**ABOUT**",
      "Project Overview"
    ]
  },
  {
    "objectID": "project-overview.html#community-contributors",
    "href": "project-overview.html#community-contributors",
    "title": "Project Overview",
    "section": "Community Contributors",
    "text": "Community Contributors\nEach Topic Guide is written by specific named contributors but we also welcome changes and contributions to this resource via logging issues or if you’re a more seasoned GitHub user, via pull requests to the github repository. A full list of contributors will be compiled here once the first edition is complete.",
    "crumbs": [
      "**ABOUT**",
      "Project Overview"
    ]
  },
  {
    "objectID": "project-overview.html#acknowledgements",
    "href": "project-overview.html#acknowledgements",
    "title": "Project Overview",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThe project team would like to thank all of our LIBER working group members who have contributed to this resource and supported our endeavours here. We have taken great inspiration from other incredible training initiatives such as the British Library Digital Scholarship Training Programme, DH Literacy Guidebook and The Programming Historian in the development of this resource and thank those projects for paving the way!",
    "crumbs": [
      "**ABOUT**",
      "Project Overview"
    ]
  },
  {
    "objectID": "contributing.html",
    "href": "contributing.html",
    "title": "Contribute to Our Project",
    "section": "",
    "text": "Ways to contribute to this project",
    "crumbs": [
      "**ABOUT**",
      "Contribute to Our Project"
    ]
  },
  {
    "objectID": "contributing.html#ways-to-contribute-to-this-project",
    "href": "contributing.html#ways-to-contribute-to-this-project",
    "title": "Contribute to Our Project",
    "section": "",
    "text": "Contribute a new Topic Guide (individually or in collaboration with others). Choose from our existing wishlist or propose a new one. Join an upcoming writing sprint or get in touch with us to discuss digitalresearch@bl.uk your idea!\nSuggest edits to an existing Topic Guide or Additional Resources by opening an Issue or adding to existing ones on the project Github.\nJoin one of the LIBER Working Groups Digital Scholarship and Digital Cultural Heritage WG or Data Science in Libraries (open to all staff of LIBER member institutions) to keep up with the developments and ongoing maintenance of this project!",
    "crumbs": [
      "**ABOUT**",
      "Contribute to Our Project"
    ]
  },
  {
    "objectID": "contributing.html#join-a-writing-sprint",
    "href": "contributing.html#join-a-writing-sprint",
    "title": "Contribute to Our Project",
    "section": "Join a Writing Sprint!",
    "text": "Join a Writing Sprint!\n\nOur first Topic Guide Sprint was held online Tuesday 14 May 2024. Our next one will be ONLINE Tuesday 03 June 2024 9:00-11:00 (BST): Register Today!\n\nIf you would like to take part please Register Today to be sent the meeting calendar invite, sprint guidance, login details and access to your Topic Guide Template in case you want to prep/get started early. Feel free to contact digitalresearch@bl.uk with any questions!\n\nPreparing for the sprint:\n\nPlease have a quick read through the Welcome and Topic Guide pages to familiarise yourself with this resource and its purpose.\nWhen you Register you’ll see a list of our latest Topic Guides on our wishlist. Please check off any and all Topic Guides you would be happy to work on during the day of the sprint. On the day each attendee will focus on writing just one Topic Guide however. The information you provide before the sprint will help us organise this ahead of time so that as many Topic Guides as possible have at least one dedicated author.\n\nPlease have a quick read through the Author Guidance and Style Guide section.\nWe’ll be in touch after we receive your registration to send you more details and useful information ahead of the sprint so look out for our email! If you are sent a copy of the Topic Guide Template (Google Doc) that corresponds to your topic of choice ahead of time, add your name to the header, and feel free to add notes or even make a start on drafting your guide before the sprint day if you’re keen!\n\n\n\nWhat to expect on the day:\nA two hour writing sprint will generally follow this format:\n\nWelcome and participant introductions (10 minutes)\n\nOverview of the project & explanation of how the day will run (15 minutes)\n\nAllocation and confirmation of individual Topic Guide Authorship for the day (15 minutes): As a group we’ll go over the wishlist and all participants will be given access to their particular Topic Guide google doc template they’ll be using during and after the sprint.\nWriting Phase (60 minutes): You’ll have an hour to begin writing your respective guide in your Google Doc template. If more than one participant are working together on a topic we can provide breakout rooms so that you can discuss amongst yourselves how to break up the work, and share ideas as you go along. You can have your camera/mic on or off during this time and co-chairs will be on hand to answer any questions or give advice on topics.\nWrapping Up & Logging progress through Github Issues (15 minutes): We have provided an Issue Template which is pre-formatted as a Topic Guide submission checklist and will walk participants through the process of opening a new issue for your draft submission. Please fill in the issue template and provide the necessary information relating to where your draft submission is currently at. Once the issue is saved, it can continue to serve as a space to continue discussion of the ongoing status of your submission and log updates where necessary, including notifying us of when it is fully ready for final review by maintainers.\nClosing Remarks & Next Steps (5 minutes)\n\n\n\nAfter the sprint:\nDuring the sprint, you’ve drafted your Topic Guide in a Google Doc. This Google Doc can continue to serve as a ‘living document’ following the sprint until you feel the content is ready to be published. Throughout this process, we will use your Github issue to maintain an overview of the docs in terms of their status and action points so please keep this updated. Each Topic Guide will be allocated a specific Maintainer contact (one of the co-chairs) who will be in touch and work with you to see the process through to completion.\nThings to note when creating and working with the Issue Template for your newly created Topic Guide:\n\nIf you want to include resources such as images and videos etc. which cannot be linked to via the web you might have to provide the files themselves to us. You can attach any local files as a comment on the Issue you have created for your Topic Guide.\nYou may request placing your Google Doc under restricted access if you wish. We will not do this by default, but we respect that some contributors would like to keep drafts private until fully ready for submission.\n\nWhen your Topic Guide is ready for our review in Google Docs, please let us know by logging an update over on Github as a comment on the Issue stating this. You can also tag the maintainers so they receive a notification as well. Maintainers will generally work with you on the final edits necessary for the submission through track changes and comments within the Google Doc itself. Once these have all been resolved maintainers will log a status update indicating “Review complete; Final Submission Ready; Make live” in the GitHub issue.",
    "crumbs": [
      "**ABOUT**",
      "Contribute to Our Project"
    ]
  },
  {
    "objectID": "contributing.html#ongoing-maintenance-and-review",
    "href": "contributing.html#ongoing-maintenance-and-review",
    "title": "Contribute to Our Project",
    "section": "Ongoing Maintenance and Review",
    "text": "Ongoing Maintenance and Review\nWe view this resource as capturing a snapshot in time and will endeavour to fully review all content a minimum of once annually to check for link rot, and content relevancy. The project team editors are committed to make quick fixes when raised throughout the year, while formal sprints and reviews coinciding with LIBER Annual Summer Conference and Winter events will be used for soliciting new content and undertaking more complex updates to the resource each year and creating new editions as necessary.\nJoin one of the LIBER Working Groups Digital Scholarship and Digital Cultural Heritage WG or Data Science in Libraries (open to all staff of LIBER member institutions) to keep up with the developments and ongoing maintenance of this project!",
    "crumbs": [
      "**ABOUT**",
      "Contribute to Our Project"
    ]
  },
  {
    "objectID": "guidelines.html",
    "href": "guidelines.html",
    "title": "Author Guidance and Style Guide",
    "section": "",
    "text": "Structuring the Topic Guide\nEach Topic Guide follows a distinct structure, beginning with a Header Section composing of a title, contributor information, published date, last modified info, and suggested citation followed by five key content blocks detailed below. Please have a look at the IIIF Guide as an example of how these pieces all fit together into one complete Topic Guide.",
    "crumbs": [
      "**ABOUT**",
      "Author Guidance and Style Guide"
    ]
  },
  {
    "objectID": "guidelines.html#structuring-the-topic-guide",
    "href": "guidelines.html#structuring-the-topic-guide",
    "title": "Author Guidance and Style Guide",
    "section": "",
    "text": "Header Section\n\nTopic Guide Title: IIIF\nContributor(s) Name and (Orcid ID): Nora McGregor (ORCID iD)\nPublished date: 27/03/2024\nSuggested Citation: Nora McGregor, “IIIF,” Digital Scholarship & Data Science Essentials for Library Professionals (2024), [DOI link]\n\nNote: The project team will ensure each Topic Guide is given an individual DOI either through British Library Research Repository or Zenodo.\n\n\nI: Introduction to the topic (Approximately 500-700 words)\nThis introduction section should be pitched at a beginner/foundational level and gives a concise overview of the topic. It should be written in a relaxed and natural way. This section does not need to contain the world’s knowledge, just enough high-level knowledge to get the key concepts across.\n\nImagine that a colleague has come to you casually asking about the topic over tea. How might you go about explaining it to them in your own words? During the course of that casual conversation what key things would you leave in and what might you leave out in the interest of getting them to a basic understanding quickly?\n\nLinking can be used liberally for jargon busting throughout if explaining a particular term is more complex than our word count allows. Please see the Style Guidelines below for more writing tips!\n\n\nII: Relevance to the Library Sector (Approximately 300-500 words)\nThis section provides a clear explanation of the topics’ specific relevance to the work of libraries.\nIt should contain:\n\nA short paragraph or two setting the scene as to why the topic is relevant to the work of libraries. Here you might also like to present opportunities and, if relevant, potential challenges for libraries around the topic as well.\nUp to 3 examples of real world (or potential) applications/case studies/projects briefly explained in a 100 max word summary provided each with links to further information if available. Note that it is not necessary to write up or create a new case study yourself here! Rather, we’re looking for briefly summarised references to existing ones. If there are quite a few other examples the contributor would like to reference include, links to these can be added at the end of this section (Example: “For further case studies, visit….”).\n\n\n\nIII: Hands-on activity and other self-guided tutorial(s)\nThe objective of this section of the topic guide is to enable learners to familiarise themselves with the basics of the topic through active practice via self-paced tutorials and hand-on activities. Authors are not expected to create new activities or tutorials in this section, but rather to provide selected links to existing hands on tutorials which are known by them to have proven value and can be personally recommended for library professionals in particular.\nThe tutorials recommended should be free, online and suitable for independent study, and ideally, focussed on the library professional perspective where possible. Authors may wish to link to practical exercises or quizzes, specific online lessons that may exist in other online platforms, Juptyer Notebooks and GLAM workbench materials that provide detailed explanations of the steps learners can follow.\nFor the sake of consistency across the various topic guides, it is helpful if tutorial references are structured as follows:\n\nThe title/name of the activity/tutorial, the URL (added as a hyperlink), and citation information (please use APA Style and/or provide a DOI if there is one)\nA brief, personal explanation below it (no more than 200 words) as to why the author recommends this particular tutorial, and, optionally, an indication of topics covered and the level of complexity.\n\n\n\nIV: Recommended Reading & Viewing (Approximately 200-400 words)\nThe section on recommended reading and viewing contains references to more passive learning resources such as:\n\nOpen access articles discussing the topic at a general level, or containing contextual information.\nVideo recordings of lectures about the topic, which do not demand practical activities from the viewer Podcasts about the topic\n\nWhen including citations please make sure to either write them in APA Style and/or simply provide the DOI with your text so that the project team can compile a dedicated Zotero Library.\n\n\nV: Taking the next steps (Approximately 200-400 words)\nThis section provides guidance to library professionals on where to take their learning journey further. It should include:\n\nWhere to find (local/national/international) Communities of Practice or other relevant networks and organisations who can help with furthering their understanding of the topic.\nIf relevant you might also point to specific summer school courses, conferences and events that may further enhance learning.",
    "crumbs": [
      "**ABOUT**",
      "Author Guidance and Style Guide"
    ]
  },
  {
    "objectID": "guidelines.html#style-guidelines",
    "href": "guidelines.html#style-guidelines",
    "title": "Author Guidance and Style Guide",
    "section": "Style Guidelines",
    "text": "Style Guidelines\n\nWriting Accessible, Natural, and Internationally Inclusive Content\nTo ensure consistency and inclusivity across our content, please consider these general guidelines:\n\nClarity and Simplicity: Write in a clear and straightforward manner, using simple language that is easy to understand for learners of all backgrounds and proficiency levels.\nLinking to Technical Terms: When introducing technical terms or concepts that may be unfamiliar to some learners, provide hyperlinks to additional resources or definitions where they can learn more. This helps to enhance understanding and allows learners to explore topics in more depth at their own pace. Ensure that the linked resources are reliable and authoritative to provide accurate information to the learners.\nAvoid Colloquialisms and Regionalisms: While it’s essential to maintain a casual and natural tone, please refrain from using colloquial expressions or regionalisms that may not be universally understood by our diverse audience.\nCultural Sensitivity: Be mindful of cultural differences and avoid language or examples that may be offensive or insensitive to any group of people. When providing examples or references, strive for universality and inclusivity.\nGender Neutrality: Use gender-neutral language whenever possible to ensure inclusivity and avoid assumptions about gender roles or identities.\nGlobal Perspective: Consider the international nature of our audience when crafting examples, scenarios, and references. Aim for content that resonates with learners from various cultural backgrounds and geographical locations.",
    "crumbs": [
      "**ABOUT**",
      "Author Guidance and Style Guide"
    ]
  },
  {
    "objectID": "licensing.html",
    "href": "licensing.html",
    "title": "Licensing & Re-use",
    "section": "",
    "text": "Citing this Resource\nSuggested citations are written in APA (American Psychological Association) citation style for Journal Articles and are given on each individual guide:\nMcGregor, Nora, “IIIF,” Digital Scholarship & Data Science Essentials for Library Professionals (2024), [DOI link]\nTo cite the full resource:\nMcGregor, N., Verhaar, P., Moopen, N., Double, J., Irollo, A., & Kiraly, P. (Eds.). (2024, March 12). Digital Scholarship & Data Science Essentials for Library Professionals. https://libereurope.github.io/ds-essentials",
    "crumbs": [
      "**ABOUT**",
      "Licensing & Re-use"
    ]
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "If you’d like to ask a question of the project team you can please send an email to Nora McGregor, nora.mcgregor@bl.uk or any of Co-Chairs and select Members of the collaborating WGs listed here who act as the core project delivery team and editors of this resource.\nJodie Double, Editor DSDCH\nPéter Király, Editor DSLib\nNora McGregor, Editor DSDCH\nNeha Moopen, Site Maintainer DSLib\nPeter Verhaar, Editor DSLib",
    "crumbs": [
      "**ABOUT**",
      "Contact"
    ]
  }
]