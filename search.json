[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Digital Scholarship & Data Science Essentials for Library Professionals",
    "section": "",
    "text": "Welcome!\nDigital Scholarship and Data Science Essentials for Library Professionals is an open and collaboratively curated training reference resource. It aims to make it easier for LIBER library professionals to gain a concise overview of the new technologies that underpin digital scholarship and data science practice in research libraries today, and find trusted training materials recommendations to start their professional learning journey.",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "index.html#our-aims",
    "href": "index.html#our-aims",
    "title": "Digital Scholarship & Data Science Essentials for Library Professionals",
    "section": "Our Aims",
    "text": "Our Aims\n\n\n\nDS Essentials Aims Summarised",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "index.html#who-is-it-for",
    "href": "index.html#who-is-it-for",
    "title": "Digital Scholarship & Data Science Essentials for Library Professionals",
    "section": "Who is it for?",
    "text": "Who is it for?\nAre you someone working in or around research libraries with an interest in learning more about how to do cool and interesting things with digital collections and data at your institution? Wondering how data science techniques can help you in your work? Are you interested in gaining valuable digital literacy skills and knowledge to support emerging areas of modern scholarship such as Digital Humanities? Do you need some of the technology jargon you hear about these days demystified?\nThen this resource is for you!\nIt is very important to us that this resource is inclusive and intellectually accessible, challenging but not terrifying and as such we focus primarily on an introductory audience where no programming or particular digital skills are required.\nThough written primarily from the research library professional perspective these guides will be useful for anyone currently (or aspiring to be) working in and around digital collections and data in heritage institutions:\n\nLibrary & Information Science students\nProject managers\nDevelopers\nInformation specialists\nMetadata Managers\nSubject librarians\nSystem librarians\nInstitutional leadership\n\nAnd so many more!",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "index.html#why-this-resource",
    "href": "index.html#why-this-resource",
    "title": "Digital Scholarship & Data Science Essentials for Library Professionals",
    "section": "Why this resource?",
    "text": "Why this resource?\nOver the past few decades, the development of excellent self-paced tutorials and training materials relating to undertaking digital scholarship and data science in libraries have proliferated online.\nFor library professionals who are relatively new to this area however, it can be hard to know where to begin! Without knowing a little bit about the context of how new technologies are being deployed in research libraries, this dearth of resources can seem quite daunting. Even if you might have an idea of what learning you’d like to undertake, it can be difficult and time consuming to try and navigate the wealth of individual training resources out there on your own.\nDigital Scholarship and Data Science Essentials for Library Professionals is a training reference resource we have developed to remove some of the barrier of having to hunt for recommended training and resources to get you on the learning ladder.\nFrom working with data, data management, digital storytelling, handwritten recognition technologies and more, our Topic Guides provide contextualised and gentle introductions, written from the library practitioners perspective, to a wide range of key topics and technologies relevant to working innovatively with our digital collections and data.",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "index.html#what-are-topic-guides",
    "href": "index.html#what-are-topic-guides",
    "title": "Digital Scholarship & Data Science Essentials for Library Professionals",
    "section": "What are Topic Guides?",
    "text": "What are Topic Guides?\nTopic Guides are the heart and soul of Digital Scholarship and Data Science Essentials for Library Professionals. The aim of each is to provide research library professionals with a gentle and concise introduction to the key topics in this area today. They offer those with no prior knowledge, quick and curated guidance to personally recommended hands-on tutorials, use-cases, articles, videos, networks and communities of practice to deepen learning.\nEach Topic Guide follows a fixed structure, consisting of five components in order to make it easier to quickly find what you might need: - Introduction to the topic - Relevance to the library sector (Case studies/Use cases) - Hands-on activities and other self-guided tutorial(s) - Recommended Reading & Viewing - Taking the next steps (Communities of Practice)",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "index.html#how-to-use-this-resource",
    "href": "index.html#how-to-use-this-resource",
    "title": "Digital Scholarship & Data Science Essentials for Library Professionals",
    "section": "How to use this resource",
    "text": "How to use this resource\nThis resource has a dual purpose; it is written as a tool for self-study but also as a guide for individuals and institutions interested in establishing their own local training programmes.\nAs a self-study resource, we hope it can serve as a useful first point of entry into complex topics in digital scholarship and data science and their application in the library world. It is not meant to be completed in any particular order, rather, learners are invited to jump in and out of individual topic guides as personal curiosity or practical need dictates.\nThe materials here can also be utilised in group study, as part of a reading group or even a hands-on Hack & Yack. See our special section on “How to start your own training programme” for some tips and tricks from British Library Digital Research Team colleagues on utilising the materials referenced here at your own library or within your network.",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "topicguides.html",
    "href": "topicguides.html",
    "title": "TOPIC GUIDES",
    "section": "",
    "text": "Topic Guides\nTopic Guides are the heart and soul of Digital Scholarship and Data Science Essentials for Library Professionals. The aim of each is to provide research library professionals with a gentle and concise introduction to the key topics in this area today. They offer those with no prior knowledge, quick and curated guidance to personally recommended hands-on tutorials, use-cases, articles, videos, networks and communities of practice to deepen learning.\nEach Topic Guide follows a fixed structure, consisting of a descriptive header and five key components in order to make it easier to quickly find the information you might need:\n\nIntroduction to the topic\nRelevance to the library sector (case studies/use cases)\nHands-on activities and other self-guided tutorial(s)\nRecommended reading & viewing\nTaking the next steps (finding Communities of Practice)\n\nThe guides are not presented, nor meant to be completed, in any particular order, rather, you are invited to jump in and out of individual topics as personal curiosity or practical need dictates.\nThe Topic Guide list in this first edition draws heavily on the existing skills framework and topics covered in the British Library’s Digital Scholarship Training Programme, as well as those recommended by attendees of a series of development workshops held with LIBER working groups throughout 2023.",
    "crumbs": [
      "**TOPIC GUIDES**"
    ]
  },
  {
    "objectID": "getting-started-with-programming.html",
    "href": "getting-started-with-programming.html",
    "title": "Getting Started With Programming",
    "section": "",
    "text": "Introduction\naergergdfvdf",
    "crumbs": [
      "Getting Started With Programming"
    ]
  },
  {
    "objectID": "getting-started-with-programming.html#relevance-to-the-library-sector",
    "href": "getting-started-with-programming.html#relevance-to-the-library-sector",
    "title": "Getting Started With Programming",
    "section": "Relevance to the Library Sector",
    "text": "Relevance to the Library Sector\naergaergaerg",
    "crumbs": [
      "Getting Started With Programming"
    ]
  },
  {
    "objectID": "getting-started-with-programming.html#hands-on-exercises-self-guided-tutorials",
    "href": "getting-started-with-programming.html#hands-on-exercises-self-guided-tutorials",
    "title": "Getting Started With Programming",
    "section": "Hands-On Exercises & Self-Guided Tutorials",
    "text": "Hands-On Exercises & Self-Guided Tutorials\naergeargaerg",
    "crumbs": [
      "Getting Started With Programming"
    ]
  },
  {
    "objectID": "getting-started-with-programming.html#recommended-reading-further-resources",
    "href": "getting-started-with-programming.html#recommended-reading-further-resources",
    "title": "Getting Started With Programming",
    "section": "Recommended Reading & Further Resources",
    "text": "Recommended Reading & Further Resources\nragergeargaergaer",
    "crumbs": [
      "Getting Started With Programming"
    ]
  },
  {
    "objectID": "r.html",
    "href": "r.html",
    "title": "R",
    "section": "",
    "text": "All things R :)",
    "crumbs": [
      "Getting Started With Programming",
      "R"
    ]
  },
  {
    "objectID": "python.html",
    "href": "python.html",
    "title": "Python",
    "section": "",
    "text": "All things Python :)",
    "crumbs": [
      "Getting Started With Programming",
      "Python"
    ]
  },
  {
    "objectID": "iiif.html",
    "href": "iiif.html",
    "title": "IIIF",
    "section": "",
    "text": "Introduction\nsdfajsdhflakjhfalkejrhf",
    "crumbs": [
      "IIIF"
    ]
  },
  {
    "objectID": "iiif.html#relevance-to-the-library-sector",
    "href": "iiif.html#relevance-to-the-library-sector",
    "title": "IIIF",
    "section": "Relevance to the Library Sector",
    "text": "Relevance to the Library Sector\nwerw4rwerw34rw",
    "crumbs": [
      "IIIF"
    ]
  },
  {
    "objectID": "iiif.html#hands-on-activities-self-guided-tutorials",
    "href": "iiif.html#hands-on-activities-self-guided-tutorials",
    "title": "IIIF",
    "section": "Hands-On Activities & Self-Guided Tutorials",
    "text": "Hands-On Activities & Self-Guided Tutorials\ndfgdfgdfgdfg",
    "crumbs": [
      "IIIF"
    ]
  },
  {
    "objectID": "iiif.html#recommended-reading-further-reading",
    "href": "iiif.html#recommended-reading-further-reading",
    "title": "IIIF",
    "section": "Recommended Reading & Further Reading",
    "text": "Recommended Reading & Further Reading\n34hjdhfbkajdhbgksjehrger",
    "crumbs": [
      "IIIF"
    ]
  },
  {
    "objectID": "llms.html",
    "href": "llms.html",
    "title": "Understanding Large Language Models",
    "section": "",
    "text": "Overview",
    "crumbs": [
      "Understanding Large Language Models"
    ]
  },
  {
    "objectID": "llms.html#overview",
    "href": "llms.html#overview",
    "title": "Understanding Large Language Models",
    "section": "",
    "text": "What are Large Language Models (LLMs)?\nA large language model (LLM) is a type of machine learning model that can perform natural language processing tasks such as generating and classifying text, answering questions, and translating text.\nIf your eyes just crossed reading that sentence, no wonder, there’s a lot of terminology and jargon to unpack there in that one little sentence. Let’s go back a few steps and take it a little slower!\nIt helps to first understand a little bit about what machine learning is. Machine learning (ML) is a core technology that underpins a lot of work in artificial intelligence work today. Artificial intelligence is actually a broad field that encompasses the development of systems and machines capable of performing tasks that typically require human intelligence, such as reasoning, problem-solving, learning, and perception, and…chatting!\nNatural Language Processing (NLP) is a specialised area within artificial intelligence (AI) that looks specifically at the challenges of processing and understanding human language (another is Computer Vision (CV) which is, on the other hand, concerned with helping computers process and understand imagery in the vein of human vision). NLP plays a vital role in enhancing the capabilities of AI systems by working to make them more capable of natural and effective interaction with humans.\nNLP involves the development of algorithms, models, and systems for analysing, understanding and extracting meaningful information from textual data representing human language. The field relies heavily on the use of machine learning to make sense of our complex textual data, which might come from literature, historical documents, articles, twitter, wikipedia, you name it!\nMachine learning involves the development of algorithms and models that allow computers to learn patterns and relationships from data and make predictions on new data. Instead of being explicitly programmed for specific tasks, ML algorithms use data to learn and improve their performance over time.\nA machine learning algorithm is designed to recognize patterns, relationships, and trends in data and will adjust their internal parameters based on examples to improve their performance over time.\nA machine learning model represents what was learned by a machine learning algorithm. The model that’s created in the process and saved after running a machine learning algorithm on training data and represents the rules, numbers, and any other algorithm-specific data structures required to make predictions on new data.\nSo back to our definition:\nA large language model (LLM) is a type of machine learning model that can perform natural language processing tasks such as generating and classifying text, answering questions, and translating text.\nLanguage models are a type of machine learning model designed to predict the likelihood of a sequence of text, which means that they can be set up to predict the most likely way to continue a conversation. The models behind ChatGPT are large, complex neural networks that have been exposed to an enormous amount of text from books, articles, websites, and more. These models have learned something about patterns in grammar and word meaning, including the way that meaning arises contextually across multiple sentences and multiple turns in a conversation. When you ask ChatGPT a question, you are presenting the model with new information it tries to make a prediction on, in this case, it tries to generate a response that matches the pattern of conversation. Large language models are trained on massive amounts of text data and are essentially the backbone of NLP today. There are and have been for many years, large language models out there actually but ChatGPT has currently caught the popular imagination because of its publicly available interface and remarkable performance.\n\n\nWhat is ChatGPT?\nChatGPT is a platform providing an interface specifically to the large language models developed by OpenAI. The GPT stands for Generative Pre-Trained Transformers which is just a fancy way of saying that the models you are chatting with have already been trained on a lot of data.\nIt's a chatbot essentially designed to generate human-like text responses based on the input it receives. Or some say to think of it as a fancy predictive text generator. You ask questions or give prompts, and it provides responses in natural language, or rather, estimates what should come next in a conversation.\n\nWhat ChatGPT is NOT:\n\nGoogle Search Box: Unlike Google, ChatGPT doesn't search the internet for information. Instead, it generates responses based on a massive dataset it was trained on. This training dataset includes large segments of text sampled from the internet at a specific point in time, and so can reflect language describing content on the internet, but it doesn't have real-time access to the internet. When ChatGPT answers a question, it isn’t actually looking up information and then composing that information into a response; it's just making an estimation of a response based on patterns it has seen. So, when you ask it factual questions, especially ones with common answers or phrases, it might give you an answer that sounds right but remember this is because it’s mimicking what it has seen in its training data. Think of it perhaps as a very smart parrot, sometimes 'repeating' things it has seen before.\nHuman Mind: ChatGPT is not a human; it's a machine learning model. It doesn't understand or reason like a human. It generates evidently linguistic responses based on patterns it learned from text data.\n\n\n\nHow ChatGPT Generates Responses:\n\nLanguage Modelling: So ChatGPT models are members of this class of models we’re talking about: “large language models” (LLMs). A machine learning model represents what was learned by a machine learning algorithm. The model is created and saved after running a machine learning algorithm on training data and represents the rules, numbers, and any other algorithm-specific data structures required to make predictions on new data. Language models are designed to predict the likelihood of a sequence of text, which means that they can be set up to predict the most likely way to continue a conversation. The models behind ChatGPT are large, complex neural networks that have been exposed to an enormous amount of text from books, articles, websites, and more. These models have learned something about patterns in grammar and word meaning, including the way that meaning arises contextually across multiple sentences and multiple turns in a conversation. When you ask ChatGPT a question, it tries to generate a response that matches these patterns.\nContextual Understanding: ChatGPT also looks at the context of the question you ask, including what’s happened so far in your conversation and any instructions or details you offer about how it should respond. It tries to understand the context and generate a response that is contextually relevant, which can make its answers seem quite accurate.\nExisting Knowledge: It can recall and blend information it has observed in its training data. So, when you ask a factual question, it can sometimes generate a response that seems factual because it has encountered similar information during training. But, it can also make mistakes or provide information that is outdated or biassed because it doesn't have the ability to verify the accuracy of what it says, and it is influenced by any views inherent in its training data, whether they are right or wrong. It's like the parrot repeating something it heard: it can't check if what it's saying is true or up-to-date. That's why it's important to double-check information output by ChatGPT with reliable sources, especially when using ChatGPT for research or critical tasks.\nUser Feedback Loop: ChatGPT models like the latest GPT-4 (openai.com) have been tuned and improved over time with user feedback, as part of a model training process known as “reinforcement learning”. So for example, when users request things like python code, and try it out, users provide feedback on whether or not it worked. This feedback helps the model get better at generating code that is more likely to work.\n\n\n\nWhen best to use ChatGPT:\n\nIdea Generation: ChatGPT can help brainstorm ideas for projects, essays, or creative endeavours. For example, you can ask it for ideas on new business ventures, book plots, or marketing campaigns.\nThesaurus and Rephrasing: It's excellent for finding synonyms, rephrasing sentences, or improving the clarity of your writing. You can ask it to provide alternative words or rewrite a paragraph for better readability.\nCreative Writing: ChatGPT can assist with creative writing tasks, including writing short stories, poems, or generating dialogues for characters.\nSome Learning and Explanation: It can provide explanations and answers to questions on a wide range of very general topics, making it useful for learning new concepts or understanding complex ideas. But again, always best to double check against other trusted resources.\nLanguage Translation: ChatGPT can offer some basic translation assistance, such as translating phrases or short sentences between languages.\nGenerating code snippets: It may not produce highly complex or critical code reliably but you can use it as a starting point for some common coding tasks.\n\n\n\nQuerying structured data: ChatGPT can provide outputs in the form of data structures including for instance SQL queries and JSON. So for instance if we have an SQL database with information about the content of a corpus, we can prompt ChatGPT to output queries that would apply to that database. We can then begin to imagine an interface where a non-expert user could make such a query using their own natural language, and ChatGPT could provide a connection with the structured data. This is sometimes referred to as “function calling” in the ChatGPT literature.",
    "crumbs": [
      "Understanding Large Language Models"
    ]
  },
  {
    "objectID": "llms.html#large-language-models-llm-and-chatgpt-uses-in-libraries-today",
    "href": "llms.html#large-language-models-llm-and-chatgpt-uses-in-libraries-today",
    "title": "Understanding Large Language Models",
    "section": "Large Language Models (LLM) and ChatGPT Uses in Libraries Today",
    "text": "Large Language Models (LLM) and ChatGPT Uses in Libraries Today\n[Need to work on this section with written examples/more narrative around opportunities and challenges]\n\nA Tech Librarian Explains How to Build AI Literacy - Choice 360\nChatGPT: Implications for academic libraries | Cox | College & Research Libraries News (acrl.org)\nUsing GPT on Library Collections (Matt Miller)\nhttps://programminghistorian.org/en/lessons/interrogating-national-narrative-gpt",
    "crumbs": [
      "Understanding Large Language Models"
    ]
  },
  {
    "objectID": "llms.html#hands-on-activity",
    "href": "llms.html#hands-on-activity",
    "title": "Understanding Large Language Models",
    "section": "Hands On Activity",
    "text": "Hands On Activity\nFor this activity we’ll primarily use the freely available ChatGPT (openai.com) interface. It’s also possible for those who may have more advanced skills to investigate using the API directly though it’s not free.\n\nWriting prompts\nTo get a useful response from ChatGPT, “prompting” is key. If you only ask a simple question, you may not be happy with the results and decide to dismiss the technology too quickly, but today’s purpose is to have a deeper play in order to develop our critical thinking and information evaluation skills, allowing us to make informed decisions about utilising tools like ChatGPT in our endeavours.\nSome best practices for writing a good prompt (helpful hints/tips gleaned from the readings above):\n\nGive the context. The more you explain the ins and outs of what you want ChatGPT to do, the more relevant your answer will be. For example, “You are an expert in [fill in the blank for your topic].”\nBe very specific and concrete about what you want it to do (and equally, what you don’t want it to do). For instance you may want to specify word count, how many items you’d like in a list, tone of voice, etc.\nGive clear instructions on what the output should look like, and be simple and concise in your language.\nProvide examples. Much like a human, ChatGPT often understands best when you provide an example for it to work with, especially if you want it to produce something that closely resembles something you’ve seen online.\nAsk ChatGPT to “act like” someone: Sometimes, it can help to start your prompt by asking ChatGPT to “act like” a certain type of person that would be particularly well-placed to respond to the query you're posing.\n\nIf you’re not satisfied with any part of the answer, you can keep building on it, asking ChatGPT to revise it in any way you like as it will continue on from previous enquiries in a session. (If you’d rather it not do that you can add “Please ignore all previous instructions” to start a prompt fresh). To learn more about prompting, there is a free online course: Learn Prompting.\n\n\nExploratory activities:\n\nHave a play generating responses to some of the below questions (or come up with your own)!\nCritically evaluate the responses you receive from ChatGPT.\n\nIs the information/response credible?\nAre there any biases in the responses?\nDoes the information align with what you know from other sources?\n\nConsider your findings, the strengths and weaknesses, ethical considerations and challenges of using AI tools such as this.\n\n\n\n\nTry this….\nExample Prompts (please share if you have come up with a useful one!)\nFurther considerations/Notes\n\n\n\n\nAsk ChatGPT to create a title for a new exhibition\n\n\n\n\nAsk ChatGPT to create an exhibition label for items in an exhibition\n“write an exhibition label for this archived website http://moorfootru nners.blogspot.co.uk/”\n\n\n\nAsk ChatGPT to create a blog post on a topic for which you are very familiar\n\n\n\n\nAsk ChatGPT to help you come up with ideas for teaching\nTry something like this:\n“You are an academic librarian focusing on instruction. Please make an outline of important topics to cover for a classroom lecture on ChatGPT. This will be part of a series of instruction sessions about information literacy. You have already worked with this class on the basic concepts of information literacy. Create the outline as a bulleted list and follow it with a classroom activity based on one of the topics you’ve discussed about ChatGPT.”\nFrom: A Tech Librarian Explains How to Build AI Literacy - Choice 36 0\nWhen you get the results, you can then ask it to give you an additional activity or set of activities on the same topic.\nHave a play around with different training subject areas.\n\n\nAsk ChatGPT to write a bio for yourself, providing it with details for instance as a list of facts about you\n\n\n\n\nAsk ChatGPT to Act as a Translator\nTry something like this:\n“I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is”istanbulu cok seviyom burada olmak cok guzel”\nFrom: Awesome ChatGPT Prompts | This repo includes ChatGPT prompt curation to use ChatGPT better. \n\n\n\nAsk ChatGPT to create an outline for a PowerPoint presentation\n\n\n\n\nAsk ChatGPT to extract metadata from a provided text\n\n\n\n\nAsk ChatGPT to write a query for a suppositional SQL database that you describe\n“We have an SQL database with the following tables: 'books' and 'authors'. The 'books' table has columns 'title', 'date', and 'topic'. The 'authors' table has columns 'name', 'birth_date', 'death_date', and 'gender'. I'm going to write some questions about things in this database, and I would like you to respond with SQL queries that would find the information I'm asking about.”\nRESPONSE: “Of course! Feel free to ask any questions you have about the database, and I'll provide you with SQL queries to retrieve the information you need. Please go ahead and ask your questions.”\nINPUT: “I'd like to find books about the second world war written by women born after the war ended.”\nRESPONSE: “To find books about the Second World War written by women born after the war ended, you can use the following SQL query:”\nSELECT b.title, b.date, a.name\nFROM books b\nJOIN authors a ON b.author_id = a.author_id\nWHERE b.topic = 'Second World War'\nAND YEAR(a.birth_date) &gt; 1945\nAND a.gender = 'female';\n\n\n\nHave a look at this project Matt Miller did experimenting with [Using GPT on Library Collections (thisismattmill er.com)]{.underlin e}\n“You are a helpful assistant that is summarizing and extracting data from a journal written by Susan B. Anthony in {RECORD_DATE_HERE}. You only answer using the text\ngiven to you. You do not make-up additional information, the answer has to be contained in the text provided to you. Each page is a diary entry or financial bookkeeping. You will structure your answer in valid JSON, if there are any quote marks in the content escape them as \".”\n“If the following text contains multiple journal entries, extract each one into an array of valid JSON dictionaries. Each dictionary represents one of the entries, extract the date and\nthe date again in the format yyyy-mm-dd and the city or state it was written in and other geographical locations mentioned that entry and people mentioned that entry and the complete\nfull text of the entry and a one sentence summary of the text, using the JSON keys dateText, dateFormated, cityOrState, geographicalLocations, people, fullText, summaryText: {FULL_TEXT_HERE}“\nThinking about this project, could you think of a similar collection that you might be able to experiment with to parse data similarly? How might you like to re-write the prompt for your own project?\n\n\nTry to use it to create social media posts\nThere is a new network called CHOSN for those working in Galleries-Libr aries-Archives-Museums (GLAM) and cultural heritage organisations as research support and research-active staff. This network is a community of practice for research support and research-active staff who work in GLAM organisations interested in developing and sharing open scholarship knowledge and skills, organising events, and supporting each other in this area. Can you write social media post for 140 character to announce this network and call people to join in?\n\n\n\nPROMPT: Act as a librarian advising a history student in the UK doing research into the third plague pandemic in India during the early 20th century. What archival resources could they use?\nRESPONSE: Certainly! If you're a history student in the UK researching the Third Plague Pandemic in India during the early 20th century, there are several archival resources you can explore to enhance your research. These archives will provide you with primary sources, documents, and historical records that can help you gain a deeper understanding of this important historical event. Here are some key archival resources to consider:\n1. **The National Archives (TNA) of the United Kingdom**:\n- TNA holds records related to British colonial administration in India during the early 20th century. Look for documents related to public health, sanitation, and official correspondence about the plague.\n2. **The India Office Records**:\n- These records are part of the British Library's holdings and contain a wealth of information on India during the colonial period. You can find reports, letters, and administrative documents related to the Third Plague Pandemic.\n3. **The British Library**:\n- The British Library has a substantial collection of materials related to India, including newspapers, periodicals, and publications from that era. You can find newspaper articles, books, and reports that discuss the plague's impact in India.\n4. **The Wellcome Collection**:\n- The Wellcome Collection in London has an extensive library and archive of materials related to the history of medicine. You may find documents, photographs, and medical reports pertaining to the plague in India.\n5. **Local Archives in India**:\n- Depending on your specific focus within India, you should also explore local archives and libraries. For example, the National Archives of India in Delhi and state archives may have valuable records.\n6. **Digital Collections**:\n- Many institutions, including the British Library and the Wellcome Collection, have digitized collections that you can access online. These digital resources can be very helpful for remote research.\n7. **University Libraries**:\n- Don't forget to check with your university's library. They may have subscriptions to digital archives and databases that can provide access to primary source materials and scholarly articles related to the Third Plague Pandemic in India.\n8. **Academic Journals**:\n- Look for scholarly articles in history and medical history journals. JSTOR and other academic databases can be valuable for finding secondary sources and research papers.\n9. **Interlibrary Loan Services**:\n- If you find a source or book that's not available in your university's library, you can request it through interlibrary loan services. This expands your access to materials from other institutions.\n10. **Archival Finding Aids**:\n- Be sure to use finding aids and catalog search tools provided by these institutions to locate specific documents and records related to the Third Plague Pandemic.\nRemember to take thorough notes, document your sources meticulously, and consult with your professors or advisors for guidance throughout your research process. Good luck with your research into this important historical topic!\n\n\n\nPROMPT: Act as an archivist producing a catalogue record for an archival document. What subject, place and name authorities or terms would you choose for the following text? [gave it c50% of the full text transcription of IO R/F/4/1754/71645]\nRESPONSE: Here's a suggested catalog record for the provided archival document, along with subject, place, and name authorities/terms:\nTitle: Development of Hemp Cultivation for Cordage Manufacturing\nAuthor: [Author's Name if available]\nDate: [Date of the Document, if available]\nDescription:\nThis archival document explores the historical development of hemp cultivation for cordage (rope) production, emphasizing its critical importance for mechanical purposes and ship rigging during the 19th century. It discusses the transition from skin and leather ropes to vegetable fiber, particularly hemp, and the widespread cultivation and commerce of hemp in various nations. The document highlights the vital role of hemp during wartime and its impact on British shipping during supply disruptions. Additionally, it underscores the attention given to hemp cultivation in India and its various applications, focusing on the Cannabis Sativa plant.\nSubjects:\nCordage Industry\nHemp Cultivation\nRope Manufacturing\nShip Rigging\nHemp Fiber\nAgriculture in India\nColonial Agriculture\nInternational Commerce\nWar Supply Chains\nMechanical Engineering\nFiber Plants\nPlaces:\nUnited Kingdom\nIndia\nNorth America\nRussia\nArabia\nPersia\nChina\nEgypt\nTurkey\nEurope\nAsia\nNames:\nAlexandre Yersin (if mentioned as the author or contributor)\nDr. Roxburgh (for his contributions to hemp cultivation in India)\nNotes:\nThis document provides historical insights into the cultivation of hemp for cordage and its significance in various regions during the 19th century, with a focus on its mechanical properties and wartime importance.\nPlease note that the specific author and date of the document were not provided in the text you provided. If this information is available, it should be included in the catalog record. Additionally, you may need to consult relevant authority files or controlled vocabularies to ensure accuracy in subject, place, and name authorities.\nCOMMENT: The inclusion of Yersin as a suggested authority is interesting / worrying, as he had cropped up in an answer to a previous question, and I had told it to disregard all of the previous conversation data before posting the cataloguing prompt…\nIn terms of indexing, it included a lot of incidental references in the text which a cataloguer would not include as subject or place index terms [should flag at this point that I did not write the BL’s catalogue entry for this]]\nI should really give it the full text before judging the description…",
    "crumbs": [
      "Understanding Large Language Models"
    ]
  },
  {
    "objectID": "llms.html#recommended-readingfurther-learning",
    "href": "llms.html#recommended-readingfurther-learning",
    "title": "Understanding Large Language Models",
    "section": "Recommended Reading/Further Learning",
    "text": "Recommended Reading/Further Learning\n\n40 Best ChatGPT Prompts You Simply Have To Try in 2023 (tech.co)\nA Tech Librarian Explains How to Build AI Literacy - Choice 360\nChatGPT: Implications for academic libraries | Cox | College & Research Libraries News (acrl.org)\nUsing GPT on Library Collections (Matt Miller)\nhttps://programminghistorian.org/en/lessons/interrogating-national-narrative-gpt\nWelcome | Learn Prompting: Your Guide to Communicating with AI\n\n\n\n\nGuide Element\nDescription\n\n\n\n\nBasic Guide Metadata |\n\n\n\nTopic title:\nUnderstanding Large Language Models through an introduction to ChatGPT\n\n\nTopic summary:\nA brief introduction to Large Language models (LLMS) by way of ChatGPT, this guide will demystify both through hands-on activities, and explore potential challenges and opportunities for current and future library services.\n\n\nAuthor(s):\nNora McGregor\n\n\nDate first published:\n16/10/2023\n\n\nDate last reviewed/Reviewed By:\n\n\n\nDate last modified:\n\n\n\nDOI:\n\n\n\nHow to cite:\n\n\n\nLearner/Skill level:\nEasy\n\n\nTopics covered\nMachine learning and AI in Libraries literacies (From controlled category tags)\n\n\nGuide Content Blocks |\n\n\n\nLearning objectives\nThis guide aims to:\n\nIntroduce [topic] and its importance in the context of library work\nOutline how these technologies are being used in libraries\nShowcase different tools & technologies relevant to [topic] through hands-on activities\nDemonstrate how [topic] can be used for [outcome]\n\n\n\nPre-requisites & set-up:\nNo previous knowledge is required. You’ll need a browser and to create a login to chatgpt. ChatGPT (openai. com)\n\n\nI: Introduction to the topic\n\n\n\nII: Relevance to the Library Sector\n\n\n\nIII: Hands-on activity and other self-guided tutorial(s)\n\n\n\nIV: Recommended Reading & Further Learning\nThis section should include reference to:\n\nRecommended reading\nNetworks/Organisations?\nAdvanced tutorials/courses/learning?",
    "crumbs": [
      "Understanding Large Language Models"
    ]
  },
  {
    "objectID": "lod.html",
    "href": "lod.html",
    "title": "Linked Open Data",
    "section": "",
    "text": "Getting Started\nThe first sections of the introductory course about Linked Open Data in cultural heritage collections, developed at Leiden University, explains the basic principles of Linked Open Data (LOD):\nA good introduction to the basic principles of Linked Open Data can also be found at the Programming historian:",
    "crumbs": [
      "Linked Open Data"
    ]
  },
  {
    "objectID": "lod.html#getting-started",
    "href": "lod.html#getting-started",
    "title": "Linked Open Data",
    "section": "",
    "text": "Basic principles\n\n\n\nIntroduction to Linked Data",
    "crumbs": [
      "Linked Open Data"
    ]
  },
  {
    "objectID": "lod.html#advanced",
    "href": "lod.html#advanced",
    "title": "Linked Open Data",
    "section": "Advanced",
    "text": "Advanced\nThe course about Linked Open Data in cultural heritage collections, developed at Leiden University also includes a tutorial about a number of tools that can be used to create and to publish LOD. More specifically, it contains discussions of the LDwizard and CLARIAH Data Legend tool ‘COW’.\nTo be able to retrieve and analyse Linked Open Data, you need to know how to build SPARQL queries. The following courses can be helpful:\n\nIntroduction to SPARQL\nUsing SPARQL to access Linked Open Data\nNote that the tutorial is somewhat outdated. The British Library SPARQL endpoint that is discussed in the text is not longer available at this address.",
    "crumbs": [
      "Linked Open Data"
    ]
  },
  {
    "objectID": "lod.html#cookbooks",
    "href": "lod.html#cookbooks",
    "title": "Linked Open Data",
    "section": "Cookbooks",
    "text": "Cookbooks\nExamples of SPARQL queries used to collect and analyse data from heritage institutions can be found in the notebooks below:\n\nThe Europeana SPARQL endpoint\nWikidata\nShort Title Catalogue of the Netherlands\nThe Dutch Institute for Art History",
    "crumbs": [
      "Linked Open Data"
    ]
  },
  {
    "objectID": "competency-frameworks.html",
    "href": "competency-frameworks.html",
    "title": "Competency Frameworks",
    "section": "",
    "text": "LIBER Digital Skills for Library Staff & Researchers Working Group - LIBER Europe. Lots of resources here, including a very useful diagram Identifying Open Science Skills for Library Staff & Researchers\nLIBER Job Description Repository\nEurope’s Digital Humanities Landscape: A Study From LIBER’s Digital Humanities & Digital Cultural Heritage Working Group",
    "crumbs": [
      "**ADDITIONAL RESOURCES**",
      "Competency Frameworks"
    ]
  },
  {
    "objectID": "networks.html",
    "href": "networks.html",
    "title": "Networks",
    "section": "",
    "text": "LIBER Data Science in Libraries Working Group\nLIBER Digital Scholarship & Digital Cultural Heritage Working Group\ncode4lib",
    "crumbs": [
      "**ADDITIONAL RESOURCES**",
      "Networks"
    ]
  },
  {
    "objectID": "reports.html",
    "href": "reports.html",
    "title": "Reports",
    "section": "",
    "text": "The British Library and the Arts and Humanities Research Council published a report on skills: Scoping Skills and Developing Training Programme for Managing Repository Services in Cultural Heritage Organisations. There is a very useful section in there that references several other digital skills frameworks for research library staff across Europe.\nALA published a report on Library Competencies.\n\nLibrary Competencies | Tools, Publications & Resources (ala.org) (USA)\nPublications and Documents - Canadian Association of Research Libraries (carl-abrc.ca) (including specifically Competencies-Final-EN-1-2.pdf (carl-abrc.ca))\n\nLippincott, Joan K. Directions in Digital Scholarship: Support for Digital, Data-Intensive, and Computational Research in Academic Libraries. Coalition for Networked Information, June 2023. https://doi.org/10.56561/ULHJ1168\nFederer L. Defining data librarianship: a survey of competencies, skills, and training. J Med Libr Assoc. 2018 Jul;106(3):294-303. doi: 10.5195/jmla.2018.306. Epub 2018 Jul 1. PMID: 29962907; PMCID: PMC6013124.",
    "crumbs": [
      "**ADDITIONAL RESOURCES**",
      "Reports"
    ]
  },
  {
    "objectID": "acknowledgements.html",
    "href": "acknowledgements.html",
    "title": "Acknowledgements",
    "section": "",
    "text": "This book and the workshop it was presented in were put together by: - Peter Verhaar (DSLib) - Nora McGregor (DSDCH) - Jodie Double (DSDCH) - Neha Moopen (DSLib)\nPeter Verhaar was the primary organizer of the workshop at the LIBER Winter Event 2023, he also provided the LOD chapter. Nora McGregor & Jodie Double provided the LLM chapter, it is featured in the British Library’s Digital Scholarship Learning Hub. Neha Moopen built the ‘book’ using Quarto & GitHub, along with input from the other contributors.",
    "crumbs": [
      "**ABOUT**",
      "Acknowledgements"
    ]
  },
  {
    "objectID": "contributing.html",
    "href": "contributing.html",
    "title": "Contributing",
    "section": "",
    "text": "In order to contribute to the book, you can refer to the chapter template that is provided in this section. The chapter template provides an outline on how to structure your contribution, so all chapters and content in the learning hub can be aligned.\nIt is possible to submit your contribution as a Word document. However, a document following Markdown syntax would be even better. The submission will then be (manually) incorporated into the book by the maintainers.\nAlternatively. you could make a ‘pull request’ on GitHub. This means writing your chapter directly on GitHub (using Markdown syntax) and requesting a review and eventual merge of your contribution. Once merged, the book will automatically be updated GitHub.",
    "crumbs": [
      "**ABOUT**",
      "Contributing"
    ]
  },
  {
    "objectID": "chapter-template.html",
    "href": "chapter-template.html",
    "title": "Chapter Template",
    "section": "",
    "text": "Guide Element\nDescription\n\n\n\n\nBasic Guide Metadata |\n\n\n\nTopic title:\n\n\n\nTopic summary:\nIn two sentences or less, summarise the guide’s purpose\n\n\nAuthor(s):\n\n\n\nDate first published:\n\n\n\nDate last reviewed/Reviewed By:\n\n\n\nDate last modified:\n\n\n\nDOI:\nEach guide should have its own DOI so that usage can be tracked.We can do this through the British Library Research Repository.\n\n\nHow to cite:\nProvide a suggested citation for the guide itself to make it easier for folks to cite.\n\n\nLearner/Skill level:\nTBD, but we should choose a standard we like that expresses the level at which this Guide is written:\nLevel I: Basic/Foundational\nLevel II: Advanced/Applied\nDifficulty: Low/Medium/High\nAwareness\nWorking\nPractitioner\nExpert\n(Digital, Data and Technology Profession Capability Framework - Capability Framework (ddat-capability-f ramework.service.gov.uk))\n\n\nTopics covered\nThese would be [controlled category tags] (https://docs.google.com/document/u/0/d/1vSIi 5WMi7icP6Byeju9UP8tmrnnASXxACOImeRr3wYU/edit) which the guide could fall under. We can base these on the list of skills categories that the WG agrees to?\n\n\nGuide Content Blocks |\n\n\n\nLearning objectives\nEach guide should have a short list of 3-4 bullet points indicating what the reader hopes to learn from going through the guide. Example:\nThis guide aims to:\n\nIntroduce [topic] and its importance in the context of library work\nOutline how these technologies are being used in libraries\nShowcase different tools & technologies relevant to [topic] through hands-on activities\nDemonstrate how [topic] can be used for [outcome]\n\n\n\nPre-requisites & set-up:\nIf there is any previous knowledge required for learning this topic, and/or any unique technology set-up required state this here.\n\n\nI: Introduction to the topic\nA concise overview of the topic, pitched at the level indicated at the outset, including jargon busting.\n\n\nII: Relevance to the Library Sector\nEach guide needs to include somewhere within it a clear explanation of the topics’ specific relevance to the work of libraries.\n\nInclude real world (or potential) applications/case studies/projects\nLay out opportunities and challenges for libraries around the topic\n\n\n\nIII: Hands-on activity and other self-guided tutorial(s)\nGuides should include one or two hands-on activities that the reader can undertake independently to practice the concepts they’re encountering. Note: not a quiz or a test\n\n\nIV: Recommended Reading & Further Learning\nThis section should include reference to:\n\nRecommended reading\nNetworks/Organisations?\nAdvanced tutorials/courses/learning?",
    "crumbs": [
      "**ABOUT**",
      "Chapter Template"
    ]
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "Feel free to reach out to Peter Verhaar (Leiden University, LIBER DSLIb WG) for any questions, ideas, feedback!",
    "crumbs": [
      "**ABOUT**",
      "Contact"
    ]
  }
]